diff --git a/pandas/core/arrays/datetimes.py b/pandas/core/arrays/datetimes.py
index 7223eda22..8e38332e6 100644
--- a/pandas/core/arrays/datetimes.py
+++ b/pandas/core/arrays/datetimes.py
@@ -1,2154 +1,1074 @@
-from datetime import datetime, time, timedelta
-from typing import Union
-import warnings
+from collections import abc
+from datetime import datetime, time
+from functools import partial
+from itertools import islice
+from typing import List, Optional, TypeVar, Union
 
 import numpy as np
-from pytz import utc
-
-from pandas._libs import lib, tslib
-from pandas._libs.tslibs import (
-    NaT,
-    Timestamp,
-    ccalendar,
-    conversion,
-    fields,
-    iNaT,
-    normalize_date,
-    resolution as libresolution,
-    timezones,
-    tzconversion,
+
+from pandas._libs import tslib, tslibs
+from pandas._libs.tslibs import Timestamp, conversion, parsing
+from pandas._libs.tslibs.parsing import (  # noqa
+    DateParseError,
+    _format_is_iso,
+    _guess_datetime_format,
 )
-from pandas.errors import PerformanceWarning
+from pandas._libs.tslibs.strptime import array_strptime
+from pandas._typing import ArrayLike
 
 from pandas.core.dtypes.common import (
-    _INT64_DTYPE,
-    _NS_DTYPE,
-    is_categorical_dtype,
-    is_datetime64_any_dtype,
+    ensure_object,
     is_datetime64_dtype,
     is_datetime64_ns_dtype,
     is_datetime64tz_dtype,
-    is_dtype_equal,
-    is_extension_array_dtype,
-    is_float_dtype,
-    is_object_dtype,
-    is_period_dtype,
-    is_string_dtype,
-    is_timedelta64_dtype,
-    pandas_dtype,
+    is_float,
+    is_integer,
+    is_integer_dtype,
+    is_list_like,
+    is_numeric_dtype,
+    is_scalar,
+)
+from pandas.core.dtypes.generic import (
+    ABCDataFrame,
+    ABCDatetimeIndex,
+    ABCIndex,
+    ABCIndexClass,
+    ABCSeries,
 )
-from pandas.core.dtypes.dtypes import DatetimeTZDtype
-from pandas.core.dtypes.generic import ABCIndexClass, ABCPandasArray, ABCSeries
-from pandas.core.dtypes.missing import isna
+from pandas.core.dtypes.missing import notna
+
+from pandas.arrays import DatetimeArray, IntegerArray
+from pandas.core import algorithms
+from pandas.core.algorithms import unique
+from pandas.core.arrays.datetimes import tz_to_dtype
+
+# ---------------------------------------------------------------------
+# types used in annotations
+
+ArrayConvertible = Union[list, tuple, ArrayLike, ABCSeries]
+Scalar = Union[int, float, str]
+DatetimeScalar = TypeVar("DatetimeScalar", Scalar, datetime)
+DatetimeScalarOrArrayConvertible = Union[
+    DatetimeScalar, list, tuple, ArrayLike, ABCSeries
+]
 
-from pandas.core.algorithms import checked_add_with_arr
-from pandas.core.arrays import datetimelike as dtl
-from pandas.core.arrays._ranges import generate_regular_range
-import pandas.core.common as com
 
-from pandas.tseries.frequencies import get_period_alias, to_offset
-from pandas.tseries.offsets import Day, Tick
+# ---------------------------------------------------------------------
 
-_midnight = time(0, 0)
 
+def _guess_datetime_format_for_array(arr, **kwargs):
+    # Try to guess the format based on the first non-NaN element
+    non_nan_elements = notna(arr).nonzero()[0]
+    if len(non_nan_elements):
+        return _guess_datetime_format(arr[non_nan_elements[0]], **kwargs)
 
-def tz_to_dtype(tz):
+
+def should_cache(
+    arg: ArrayConvertible, unique_share: float = 0.7, check_count: Optional[int] = None
+) -> bool:
     """
-    Return a datetime64[ns] dtype appropriate for the given timezone.
+    Decides whether to do caching.
+
+    If the percent of unique elements among `check_count` elements less
+    than `unique_share * 100` then we can do caching.
 
     Parameters
     ----------
-    tz : tzinfo or None
+    arg: listlike, tuple, 1-d array, Series
+    unique_share: float, default=0.7, optional
+        0 < unique_share < 1
+    check_count: int, optional
+        0 <= check_count <= len(arg)
 
     Returns
     -------
-    np.dtype or Datetime64TZDType
-    """
-    if tz is None:
-        return _NS_DTYPE
-    else:
-        return DatetimeTZDtype(tz=tz)
-
-
-def _field_accessor(name, field, docstring=None):
-    def f(self):
-        values = self.asi8
-        if self.tz is not None and not timezones.is_utc(self.tz):
-            values = self._local_timestamps()
-
-        if field in self._bool_ops:
-            if field.endswith(("start", "end")):
-                freq = self.freq
-                month_kw = 12
-                if freq:
-                    kwds = freq.kwds
-                    month_kw = kwds.get("startingMonth", kwds.get("month", 12))
-
-                result = fields.get_start_end_field(
-                    values, field, self.freqstr, month_kw
-                )
-            else:
-                result = fields.get_date_field(values, field)
+    do_caching: bool
 
-            # these return a boolean by-definition
-            return result
+    Notes
+    -----
+    By default for a sequence of less than 50 items in size, we don't do
+    caching; for the number of elements less than 5000, we take ten percent of
+    all elements to check for a uniqueness share; if the sequence size is more
+    than 5000, then we check only the first 500 elements.
+    All constants were chosen empirically by.
+    """
+    do_caching = True
 
-        if field in self._object_ops:
-            result = fields.get_date_name_field(values, field)
-            result = self._maybe_mask_results(result, fill_value=None)
+    # default realization
+    if check_count is None:
+        # in this case, the gain from caching is negligible
+        if len(arg) <= 50:
+            return False
 
+        if len(arg) <= 5000:
+            check_count = int(len(arg) * 0.1)
         else:
-            result = fields.get_date_field(values, field)
-            result = self._maybe_mask_results(
-                result, fill_value=None, convert="float64"
-            )
+            check_count = 500
+    else:
+        assert (
+            0 <= check_count <= len(arg)
+        ), "check_count must be in next bounds: [0; len(arg)]"
+        if check_count == 0:
+            return False
 
-        return result
+    assert 0 < unique_share < 1, "unique_share must be in next bounds: (0; 1)"
 
-    f.__name__ = name
-    f.__doc__ = docstring
-    return property(f)
+    unique_elements = set(islice(arg, check_count))
+    if len(unique_elements) > check_count * unique_share:
+        do_caching = False
+    return do_caching
 
 
-class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps):
+def _maybe_cache(arg, format, cache, convert_listlike):
     """
-    Pandas ExtensionArray for tz-naive or tz-aware datetime data.
-
-    .. versionadded:: 0.24.0
-
-    .. warning::
-
-       DatetimeArray is currently experimental, and its API may change
-       without warning. In particular, :attr:`DatetimeArray.dtype` is
-       expected to change to always be an instance of an ``ExtensionDtype``
-       subclass.
+    Create a cache of unique dates from an array of dates
 
     Parameters
     ----------
-    values : Series, Index, DatetimeArray, ndarray
-        The datetime data.
+    arg : listlike, tuple, 1-d array, Series
+    format : string
+        Strftime format to parse time
+    cache : boolean
+        True attempts to create a cache of converted values
+    convert_listlike : function
+        Conversion function to apply on dates
 
-        For DatetimeArray `values` (or a Series or Index boxing one),
-        `dtype` and `freq` will be extracted from `values`.
-
-    dtype : numpy.dtype or DatetimeTZDtype
-        Note that the only NumPy dtype allowed is 'datetime64[ns]'.
-    freq : str or Offset, optional
-        The frequency.
-    copy : bool, default False
-        Whether to copy the underlying array of values.
-
-    Attributes
-    ----------
-    None
-
-    Methods
+    Returns
     -------
-    None
+    cache_array : Series
+        Cache of converted, unique dates. Can be empty
     """
+    from pandas import Series
 
-    _typ = "datetimearray"
-    _scalar_type = Timestamp
-    _recognized_scalars = (datetime, np.datetime64)
-    _is_recognized_dtype = is_datetime64_any_dtype
-
-    # define my properties & methods for delegation
-    _bool_ops = [
-        "is_month_start",
-        "is_month_end",
-        "is_quarter_start",
-        "is_quarter_end",
-        "is_year_start",
-        "is_year_end",
-        "is_leap_year",
-    ]
-    _object_ops = ["freq", "tz"]
-    _field_ops = [
-        "year",
-        "month",
-        "day",
-        "hour",
-        "minute",
-        "second",
-        "weekofyear",
-        "week",
-        "weekday",
-        "dayofweek",
-        "dayofyear",
-        "quarter",
-        "days_in_month",
-        "daysinmonth",
-        "microsecond",
-        "nanosecond",
-    ]
-    _other_ops = ["date", "time", "timetz"]
-    _datetimelike_ops = _field_ops + _object_ops + _bool_ops + _other_ops
-    _datetimelike_methods = [
-        "to_period",
-        "tz_localize",
-        "tz_convert",
-        "normalize",
-        "strftime",
-        "round",
-        "floor",
-        "ceil",
-        "month_name",
-        "day_name",
-    ]
-
-    # ndim is inherited from ExtensionArray, must exist to ensure
-    #  Timestamp.__richcmp__(DateTimeArray) operates pointwise
-
-    # ensure that operations with numpy arrays defer to our implementation
-    __array_priority__ = 1000
-
-    # -----------------------------------------------------------------
-    # Constructors
-
-    _dtype: Union[np.dtype, DatetimeTZDtype]
-    _freq = None
-
-    def __init__(self, values, dtype=_NS_DTYPE, freq=None, copy=False):
-        if isinstance(values, (ABCSeries, ABCIndexClass)):
-            values = values._values
-
-        inferred_freq = getattr(values, "_freq", None)
-
-        if isinstance(values, type(self)):
-            # validation
-            dtz = getattr(dtype, "tz", None)
-            if dtz and values.tz is None:
-                dtype = DatetimeTZDtype(tz=dtype.tz)
-            elif dtz and values.tz:
-                if not timezones.tz_compare(dtz, values.tz):
-                    msg = (
-                        "Timezone of the array and 'dtype' do not match. "
-                        f"'{dtz}' != '{values.tz}'"
-                    )
-                    raise TypeError(msg)
-            elif values.tz:
-                dtype = values.dtype
-
-            if freq is None:
-                freq = values.freq
-            values = values._data
-
-        if not isinstance(values, np.ndarray):
-            raise ValueError(
-                f"Unexpected type '{type(values).__name__}'. 'values' must be "
-                "a DatetimeArray ndarray, or Series or Index containing one of those."
-            )
-        if values.ndim not in [1, 2]:
-            raise ValueError("Only 1-dimensional input arrays are supported.")
-
-        if values.dtype == "i8":
-            # for compat with datetime/timedelta/period shared methods,
-            #  we can sometimes get here with int64 values.  These represent
-            #  nanosecond UTC (or tz-naive) unix timestamps
-            values = values.view(_NS_DTYPE)
-
-        if values.dtype != _NS_DTYPE:
-            raise ValueError(
-                "The dtype of 'values' is incorrect. Must be 'datetime64[ns]'. "
-                f"Got {values.dtype} instead."
-            )
-
-        dtype = _validate_dt64_dtype(dtype)
-
-        if freq == "infer":
-            raise ValueError(
-                "Frequency inference not allowed in DatetimeArray.__init__. "
-                "Use 'pd.array()' instead."
-            )
-
-        if copy:
-            values = values.copy()
-        if freq:
-            freq = to_offset(freq)
-        if getattr(dtype, "tz", None):
-            # https://github.com/pandas-dev/pandas/issues/18595
-            # Ensure that we have a standard timezone for pytz objects.
-            # Without this, things like adding an array of timedeltas and
-            # a  tz-aware Timestamp (with a tz specific to its datetime) will
-            # be incorrect(ish?) for the array as a whole
-            dtype = DatetimeTZDtype(tz=timezones.tz_standardize(dtype.tz))
-
-        self._data = values
-        self._dtype = dtype
-        self._freq = freq
-
-        if inferred_freq is None and freq is not None:
-            type(self)._validate_frequency(self, freq)
-
-    @classmethod
-    def _simple_new(cls, values, freq=None, dtype=_NS_DTYPE):
-        assert isinstance(values, np.ndarray)
-        if values.dtype != _NS_DTYPE:
-            assert values.dtype == "i8"
-            values = values.view(_NS_DTYPE)
-
-        result = object.__new__(cls)
-        result._data = values
-        result._freq = freq
-        result._dtype = dtype
-        return result
-
-    @classmethod
-    def _from_sequence(
-        cls,
-        data,
-        dtype=None,
-        copy=False,
-        tz=None,
-        freq=None,
-        dayfirst=False,
-        yearfirst=False,
-        ambiguous="raise",
-    ):
-
-        freq, freq_infer = dtl.maybe_infer_freq(freq)
-
-        subarr, tz, inferred_freq = sequence_to_dt64ns(
-            data,
-            dtype=dtype,
-            copy=copy,
-            tz=tz,
-            dayfirst=dayfirst,
-            yearfirst=yearfirst,
-            ambiguous=ambiguous,
-        )
+    cache_array = Series(dtype=object)
 
-        freq, freq_infer = dtl.validate_inferred_freq(freq, inferred_freq, freq_infer)
+    if cache:
+        # Perform a quicker unique check
+        if not should_cache(arg):
+            return cache_array
 
-        dtype = tz_to_dtype(tz)
-        result = cls._simple_new(subarr, freq=freq, dtype=dtype)
+        unique_dates = unique(arg)
+        if len(unique_dates) < len(arg):
+            cache_dates = convert_listlike(unique_dates, format)
+            cache_array = Series(cache_dates, index=unique_dates)
+    return cache_array
 
-        if inferred_freq is None and freq is not None:
-            # this condition precludes `freq_infer`
-            cls._validate_frequency(result, freq, ambiguous=ambiguous)
-
-        elif freq_infer:
-            # Set _freq directly to bypass duplicative _validate_frequency
-            # check.
-            result._freq = to_offset(result.inferred_freq)
-
-        return result
-
-    @classmethod
-    def _generate_range(
-        cls,
-        start,
-        end,
-        periods,
-        freq,
-        tz=None,
-        normalize=False,
-        ambiguous="raise",
-        nonexistent="raise",
-        closed=None,
-    ):
-
-        periods = dtl.validate_periods(periods)
-        if freq is None and any(x is None for x in [periods, start, end]):
-            raise ValueError("Must provide freq argument if no data is supplied")
-
-        if com.count_not_none(start, end, periods, freq) != 3:
-            raise ValueError(
-                "Of the four parameters: start, end, periods, "
-                "and freq, exactly three must be specified"
-            )
-        freq = to_offset(freq)
 
-        if start is not None:
-            start = Timestamp(start)
+def _box_as_indexlike(
+    dt_array: ArrayLike, utc: Optional[bool] = None, name: Optional[str] = None
+) -> Union[ABCIndex, ABCDatetimeIndex]:
+    """
+    Properly boxes the ndarray of datetimes to DatetimeIndex
+    if it is possible or to generic Index instead
 
-        if end is not None:
-            end = Timestamp(end)
+    Parameters
+    ----------
+    dt_array: 1-d array
+        Array of datetimes to be wrapped in an Index.
+    tz : object
+        None or 'utc'
+    name : string, default None
+        Name for a resulting index
 
-        if start is None and end is None:
-            if closed is not None:
-                raise ValueError(
-                    "Closed has to be None if not both of start and end are defined"
-                )
-        if start is NaT or end is NaT:
-            raise ValueError("Neither `start` nor `end` can be NaT")
+    Returns
+    -------
+    result : datetime of converted dates
+        - DatetimeIndex if convertible to sole datetime64 type
+        - general Index otherwise
+    """
+    from pandas import DatetimeIndex, Index
 
-        left_closed, right_closed = dtl.validate_endpoints(closed)
+    if is_datetime64_dtype(dt_array):
+        tz = "utc" if utc else None
+        return DatetimeIndex(dt_array, tz=tz, name=name)
+    return Index(dt_array, name=name)
 
-        start, end, _normalized = _maybe_normalize_endpoints(start, end, normalize)
 
-        tz = _infer_tz_from_endpoints(start, end, tz)
+def _convert_and_box_cache(
+    arg: DatetimeScalarOrArrayConvertible,
+    cache_array: ABCSeries,
+    name: Optional[str] = None,
+) -> ABCIndexClass:
+    """
+    Convert array of dates with a cache and wrap the result in an Index.
 
-        if tz is not None:
-            # Localize the start and end arguments
-            start = _maybe_localize_point(
-                start,
-                getattr(start, "tz", None),
-                start,
-                freq,
-                tz,
-                ambiguous,
-                nonexistent,
-            )
-            end = _maybe_localize_point(
-                end, getattr(end, "tz", None), end, freq, tz, ambiguous, nonexistent
-            )
-        if freq is not None:
-            # We break Day arithmetic (fixed 24 hour) here and opt for
-            # Day to mean calendar day (23/24/25 hour). Therefore, strip
-            # tz info from start and day to avoid DST arithmetic
-            if isinstance(freq, Day):
-                if start is not None:
-                    start = start.tz_localize(None)
-                if end is not None:
-                    end = end.tz_localize(None)
-            # TODO: consider re-implementing _cached_range; GH#17914
-            values, _tz = generate_regular_range(start, end, periods, freq)
-            index = cls._simple_new(values, freq=freq, dtype=tz_to_dtype(_tz))
-
-            if tz is not None and index.tz is None:
-                arr = conversion.tz_localize_to_utc(
-                    index.asi8, tz, ambiguous=ambiguous, nonexistent=nonexistent
-                )
-
-                index = cls(arr)
-
-                # index is localized datetime64 array -> have to convert
-                # start/end as well to compare
-                if start is not None:
-                    start = start.tz_localize(tz).asm8
-                if end is not None:
-                    end = end.tz_localize(tz).asm8
-        else:
-            # Create a linearly spaced date_range in local time
-            # Nanosecond-granularity timestamps aren't always correctly
-            # representable with doubles, so we limit the range that we
-            # pass to np.linspace as much as possible
-            arr = (
-                np.linspace(0, end.value - start.value, periods, dtype="int64")
-                + start.value
-            )
-            dtype = tz_to_dtype(tz)
-            index = cls._simple_new(
-                arr.astype("M8[ns]", copy=False), freq=None, dtype=dtype
-            )
+    Parameters
+    ----------
+    arg : integer, float, string, datetime, list, tuple, 1-d array, Series
+    cache_array : Series
+        Cache of converted, unique dates
+    name : string, default None
+        Name for a DatetimeIndex
 
-        if not left_closed and len(index) and index[0] == start:
-            index = index[1:]
-        if not right_closed and len(index) and index[-1] == end:
-            index = index[:-1]
-
-        dtype = tz_to_dtype(tz)
-        return cls._simple_new(index.asi8, freq=freq, dtype=dtype)
-
-    # -----------------------------------------------------------------
-    # DatetimeLike Interface
-
-    def _unbox_scalar(self, value):
-        if not isinstance(value, self._scalar_type) and value is not NaT:
-            raise ValueError("'value' should be a Timestamp.")
-        if not isna(value):
-            self._check_compatible_with(value)
-        return value.value
-
-    def _scalar_from_string(self, value):
-        return Timestamp(value, tz=self.tz)
-
-    def _check_compatible_with(self, other, setitem: bool = False):
-        if other is NaT:
-            return
-        self._assert_tzawareness_compat(other)
-        if setitem:
-            # Stricter check for setitem vs comparison methods
-            if not timezones.tz_compare(self.tz, other.tz):
-                raise ValueError(f"Timezones don't match. '{self.tz} != {other.tz}'")
-
-    def _maybe_clear_freq(self):
-        self._freq = None
-
-    # -----------------------------------------------------------------
-    # Descriptive Properties
-
-    @property
-    def _box_func(self):
-        return lambda x: Timestamp(x, freq=self.freq, tz=self.tz)
-
-    @property
-    def dtype(self) -> Union[np.dtype, DatetimeTZDtype]:
-        """
-        The dtype for the DatetimeArray.
-
-        .. warning::
-
-           A future version of pandas will change dtype to never be a
-           ``numpy.dtype``. Instead, :attr:`DatetimeArray.dtype` will
-           always be an instance of an ``ExtensionDtype`` subclass.
-
-        Returns
-        -------
-        numpy.dtype or DatetimeTZDtype
-            If the values are tz-naive, then ``np.dtype('datetime64[ns]')``
-            is returned.
-
-            If the values are tz-aware, then the ``DatetimeTZDtype``
-            is returned.
-        """
-        return self._dtype
-
-    @property
-    def tz(self):
-        """
-        Return timezone, if any.
-
-        Returns
-        -------
-        datetime.tzinfo, pytz.tzinfo.BaseTZInfo, dateutil.tz.tz.tzfile, or None
-            Returns None when the array is tz-naive.
-        """
-        # GH 18595
-        return getattr(self.dtype, "tz", None)
-
-    @tz.setter
-    def tz(self, value):
-        # GH 3746: Prevent localizing or converting the index by setting tz
-        raise AttributeError(
-            "Cannot directly set timezone. Use tz_localize() "
-            "or tz_convert() as appropriate"
-        )
+    Returns
+    -------
+    result : Index-like of converted dates
+    """
+    from pandas import Series
 
-    @property
-    def tzinfo(self):
-        """
-        Alias for tz attribute
-        """
-        return self.tz
-
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def _timezone(self):
-        """
-        Comparable timezone both for pytz / dateutil
-        """
-        return timezones.get_timezone(self.tzinfo)
-
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def is_normalized(self):
-        """
-        Returns True if all of the dates are at midnight ("no time")
-        """
-        return conversion.is_date_array_normalized(self.asi8, self.tz)
-
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def _resolution(self):
-        return libresolution.resolution(self.asi8, self.tz)
-
-    # ----------------------------------------------------------------
-    # Array-Like / EA-Interface Methods
-
-    def __array__(self, dtype=None) -> np.ndarray:
-        if dtype is None and self.tz:
-            # The default for tz-aware is object, to preserve tz info
-            dtype = object
-
-        return super().__array__(dtype=dtype)
-
-    def __iter__(self):
-        """
-        Return an iterator over the boxed values
-
-        Yields
-        ------
-        tstamp : Timestamp
-        """
-
-        # convert in chunks of 10k for efficiency
-        data = self.asi8
-        length = len(self)
-        chunksize = 10000
-        chunks = int(length / chunksize) + 1
-        for i in range(chunks):
-            start_i = i * chunksize
-            end_i = min((i + 1) * chunksize, length)
-            converted = tslib.ints_to_pydatetime(
-                data[start_i:end_i], tz=self.tz, freq=self.freq, box="timestamp"
-            )
-            for v in converted:
-                yield v
-
-    def astype(self, dtype, copy=True):
-        # We handle
-        #   --> datetime
-        #   --> period
-        # DatetimeLikeArrayMixin Super handles the rest.
-        dtype = pandas_dtype(dtype)
-
-        if is_datetime64_ns_dtype(dtype) and not is_dtype_equal(dtype, self.dtype):
-            # GH#18951: datetime64_ns dtype but not equal means different tz
-            new_tz = getattr(dtype, "tz", None)
-            if getattr(self.dtype, "tz", None) is None:
-                return self.tz_localize(new_tz)
-            result = self.tz_convert(new_tz)
-            if copy:
-                result = result.copy()
-            if new_tz is None:
-                # Do we want .astype('datetime64[ns]') to be an ndarray.
-                # The astype in Block._astype expects this to return an
-                # ndarray, but we could maybe work around it there.
-                result = result._data
-            return result
-        elif is_datetime64tz_dtype(self.dtype) and is_dtype_equal(self.dtype, dtype):
-            if copy:
-                return self.copy()
-            return self
-        elif is_period_dtype(dtype):
-            return self.to_period(freq=dtype.freq)
-        return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy)
+    result = Series(arg).map(cache_array)
+    return _box_as_indexlike(result, utc=None, name=name)
 
-    # -----------------------------------------------------------------
-    # Rendering Methods
 
-    def _format_native_types(self, na_rep="NaT", date_format=None, **kwargs):
-        from pandas.io.formats.format import _get_format_datetime64_from_values
+def _return_parsed_timezone_results(result, timezones, tz, name):
+    """
+    Return results from array_strptime if a %z or %Z directive was passed.
 
-        fmt = _get_format_datetime64_from_values(self, date_format)
+    Parameters
+    ----------
+    result : ndarray
+        int64 date representations of the dates
+    timezones : ndarray
+        pytz timezone objects
+    tz : object
+        None or pytz timezone object
+    name : string, default None
+        Name for a DatetimeIndex
 
-        return tslib.format_array_from_datetime(
-            self.asi8, tz=self.tz, format=fmt, na_rep=na_rep
+    Returns
+    -------
+    tz_result : Index-like of parsed dates with timezone
+    """
+    if tz is not None:
+        raise ValueError(
+            "Cannot pass a tz argument when parsing strings with timezone information."
         )
+    tz_results = np.array(
+        [Timestamp(res).tz_localize(zone) for res, zone in zip(result, timezones)]
+    )
+    from pandas import Index
 
-    # -----------------------------------------------------------------
-    # Comparison Methods
-
-    def _has_same_tz(self, other):
-        zzone = self._timezone
-
-        # vzone shouldn't be None if value is non-datetime like
-        if isinstance(other, np.datetime64):
-            # convert to Timestamp as np.datetime64 doesn't have tz attr
-            other = Timestamp(other)
-        vzone = timezones.get_timezone(getattr(other, "tzinfo", "__no_tz__"))
-        return zzone == vzone
-
-    def _assert_tzawareness_compat(self, other):
-        # adapted from _Timestamp._assert_tzawareness_compat
-        other_tz = getattr(other, "tzinfo", None)
-        if is_datetime64tz_dtype(other):
-            # Get tzinfo from Series dtype
-            other_tz = other.dtype.tz
-        if other is NaT:
-            # pd.NaT quacks both aware and naive
-            pass
-        elif self.tz is None:
-            if other_tz is not None:
-                raise TypeError(
-                    "Cannot compare tz-naive and tz-aware datetime-like objects."
-                )
-        elif other_tz is None:
-            raise TypeError(
-                "Cannot compare tz-naive and tz-aware datetime-like objects"
-            )
-
-    # -----------------------------------------------------------------
-    # Arithmetic Methods
-
-    def _sub_datetime_arraylike(self, other):
-        """subtract DatetimeArray/Index or ndarray[datetime64]"""
-        if len(self) != len(other):
-            raise ValueError("cannot add indices of unequal length")
-
-        if isinstance(other, np.ndarray):
-            assert is_datetime64_dtype(other)
-            other = type(self)(other)
-
-        if not self._has_same_tz(other):
-            # require tz compat
-            raise TypeError(
-                f"{type(self).__name__} subtraction must have the same "
-                "timezones or no timezones"
-            )
-
-        self_i8 = self.asi8
-        other_i8 = other.asi8
-        arr_mask = self._isnan | other._isnan
-        new_values = checked_add_with_arr(self_i8, -other_i8, arr_mask=arr_mask)
-        if self._hasnans or other._hasnans:
-            new_values[arr_mask] = iNaT
-        return new_values.view("timedelta64[ns]")
+    return Index(tz_results, name=name)
 
-    def _add_offset(self, offset):
-        if self.ndim == 2:
-            return self.ravel()._add_offset(offset).reshape(self.shape)
 
-        assert not isinstance(offset, Tick)
-        try:
-            if self.tz is not None:
-                values = self.tz_localize(None)
-            else:
-                values = self
-            result = offset.apply_index(values).tz_localize(self.tz)
-
-        except NotImplementedError:
-            warnings.warn(
-                "Non-vectorized DateOffset being applied to Series or DatetimeIndex",
-                PerformanceWarning,
-            )
-            result = self.astype("O") + offset
-            if not len(self):
-                # GH#30336 _from_sequence won't be able to infer self.tz
-                return type(self)._from_sequence(result).tz_localize(self.tz)
-
-        return type(self)._from_sequence(result, freq="infer")
-
-    def _sub_datetimelike_scalar(self, other):
-        # subtract a datetime from myself, yielding a ndarray[timedelta64[ns]]
-        assert isinstance(other, (datetime, np.datetime64))
-        assert other is not NaT
-        other = Timestamp(other)
-        if other is NaT:
-            return self - NaT
-
-        if not self._has_same_tz(other):
-            # require tz compat
-            raise TypeError(
-                "Timestamp subtraction must have the same timezones or no timezones"
-            )
+def _convert_listlike_datetimes(
+    arg,
+    format,
+    name=None,
+    tz=None,
+    unit=None,
+    errors=None,
+    infer_datetime_format=None,
+    dayfirst=None,
+    yearfirst=None,
+    exact=None,
+):
+    """
+    Helper function for to_datetime. Performs the conversions of 1D listlike
+    of dates
 
-        i8 = self.asi8
-        result = checked_add_with_arr(i8, -other.value, arr_mask=self._isnan)
-        result = self._maybe_mask_results(result)
-        return result.view("timedelta64[ns]")
-
-    def _add_delta(self, delta):
-        """
-        Add a timedelta-like, Tick, or TimedeltaIndex-like object
-        to self, yielding a new DatetimeArray
-
-        Parameters
-        ----------
-        other : {timedelta, np.timedelta64, Tick,
-                 TimedeltaIndex, ndarray[timedelta64]}
-
-        Returns
-        -------
-        result : DatetimeArray
-        """
-        new_values = super()._add_delta(delta)
-        return type(self)._from_sequence(new_values, tz=self.tz, freq="infer")
-
-    # -----------------------------------------------------------------
-    # Timezone Conversion and Localization Methods
-
-    def _local_timestamps(self):
-        """
-        Convert to an i8 (unix-like nanosecond timestamp) representation
-        while keeping the local timezone and not using UTC.
-        This is used to calculate time-of-day information as if the timestamps
-        were timezone-naive.
-        """
-        return tzconversion.tz_convert(self.asi8, utc, self.tz)
-
-    def tz_convert(self, tz):
-        """
-        Convert tz-aware Datetime Array/Index from one time zone to another.
-
-        Parameters
-        ----------
-        tz : str, pytz.timezone, dateutil.tz.tzfile or None
-            Time zone for time. Corresponding timestamps would be converted
-            to this time zone of the Datetime Array/Index. A `tz` of None will
-            convert to UTC and remove the timezone information.
-
-        Returns
-        -------
-        Array or Index
-
-        Raises
-        ------
-        TypeError
-            If Datetime Array/Index is tz-naive.
-
-        See Also
-        --------
-        DatetimeIndex.tz : A timezone that has a variable offset from UTC.
-        DatetimeIndex.tz_localize : Localize tz-naive DatetimeIndex to a
-            given time zone, or remove timezone from a tz-aware DatetimeIndex.
-
-        Examples
-        --------
-        With the `tz` parameter, we can change the DatetimeIndex
-        to other time zones:
-
-        >>> dti = pd.date_range(start='2014-08-01 09:00',
-        ...                     freq='H', periods=3, tz='Europe/Berlin')
-
-        >>> dti
-        DatetimeIndex(['2014-08-01 09:00:00+02:00',
-                       '2014-08-01 10:00:00+02:00',
-                       '2014-08-01 11:00:00+02:00'],
-                      dtype='datetime64[ns, Europe/Berlin]', freq='H')
-
-        >>> dti.tz_convert('US/Central')
-        DatetimeIndex(['2014-08-01 02:00:00-05:00',
-                       '2014-08-01 03:00:00-05:00',
-                       '2014-08-01 04:00:00-05:00'],
-                      dtype='datetime64[ns, US/Central]', freq='H')
-
-        With the ``tz=None``, we can remove the timezone (after converting
-        to UTC if necessary):
-
-        >>> dti = pd.date_range(start='2014-08-01 09:00', freq='H',
-        ...                     periods=3, tz='Europe/Berlin')
-
-        >>> dti
-        DatetimeIndex(['2014-08-01 09:00:00+02:00',
-                       '2014-08-01 10:00:00+02:00',
-                       '2014-08-01 11:00:00+02:00'],
-                        dtype='datetime64[ns, Europe/Berlin]', freq='H')
-
-        >>> dti.tz_convert(None)
-        DatetimeIndex(['2014-08-01 07:00:00',
-                       '2014-08-01 08:00:00',
-                       '2014-08-01 09:00:00'],
-                        dtype='datetime64[ns]', freq='H')
-        """
-        tz = timezones.maybe_get_tz(tz)
-
-        if self.tz is None:
-            # tz naive, use tz_localize
-            raise TypeError(
-                "Cannot convert tz-naive timestamps, use tz_localize to localize"
-            )
+    Parameters
+    ----------
+    arg : list, tuple, ndarray, Series, Index
+        date to be parced
+    name : object
+        None or string for the Index name
+    tz : object
+        None or 'utc'
+    unit : string
+        None or string of the frequency of the passed data
+    errors : string
+        error handing behaviors from to_datetime, 'raise', 'coerce', 'ignore'
+    infer_datetime_format : boolean
+        inferring format behavior from to_datetime
+    dayfirst : boolean
+        dayfirst parsing behavior from to_datetime
+    yearfirst : boolean
+        yearfirst parsing behavior from to_datetime
+    exact : boolean
+        exact format matching behavior from to_datetime
 
-        # No conversion since timestamps are all UTC to begin with
-        dtype = tz_to_dtype(tz)
-        return self._simple_new(self.asi8, dtype=dtype, freq=self.freq)
-
-    def tz_localize(self, tz, ambiguous="raise", nonexistent="raise"):
-        """
-        Localize tz-naive Datetime Array/Index to tz-aware
-        Datetime Array/Index.
-
-        This method takes a time zone (tz) naive Datetime Array/Index object
-        and makes this time zone aware. It does not move the time to another
-        time zone.
-        Time zone localization helps to switch from time zone aware to time
-        zone unaware objects.
-
-        Parameters
-        ----------
-        tz : str, pytz.timezone, dateutil.tz.tzfile or None
-            Time zone to convert timestamps to. Passing ``None`` will
-            remove the time zone information preserving local time.
-        ambiguous : 'infer', 'NaT', bool array, default 'raise'
-            When clocks moved backward due to DST, ambiguous times may arise.
-            For example in Central European Time (UTC+01), when going from
-            03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at
-            00:30:00 UTC and at 01:30:00 UTC. In such a situation, the
-            `ambiguous` parameter dictates how ambiguous times should be
-            handled.
-
-            - 'infer' will attempt to infer fall dst-transition hours based on
-              order
-            - bool-ndarray where True signifies a DST time, False signifies a
-              non-DST time (note that this flag is only applicable for
-              ambiguous times)
-            - 'NaT' will return NaT where there are ambiguous times
-            - 'raise' will raise an AmbiguousTimeError if there are ambiguous
-              times.
-
-        nonexistent : 'shift_forward', 'shift_backward, 'NaT', timedelta, \
-default 'raise'
-            A nonexistent time does not exist in a particular timezone
-            where clocks moved forward due to DST.
-
-            - 'shift_forward' will shift the nonexistent time forward to the
-              closest existing time
-            - 'shift_backward' will shift the nonexistent time backward to the
-              closest existing time
-            - 'NaT' will return NaT where there are nonexistent times
-            - timedelta objects will shift nonexistent times by the timedelta
-            - 'raise' will raise an NonExistentTimeError if there are
-              nonexistent times.
-
-            .. versionadded:: 0.24.0
-
-        Returns
-        -------
-        Same type as self
-            Array/Index converted to the specified time zone.
-
-        Raises
-        ------
-        TypeError
-            If the Datetime Array/Index is tz-aware and tz is not None.
-
-        See Also
-        --------
-        DatetimeIndex.tz_convert : Convert tz-aware DatetimeIndex from
-            one time zone to another.
-
-        Examples
-        --------
-        >>> tz_naive = pd.date_range('2018-03-01 09:00', periods=3)
-        >>> tz_naive
-        DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',
-                       '2018-03-03 09:00:00'],
-                      dtype='datetime64[ns]', freq='D')
-
-        Localize DatetimeIndex in US/Eastern time zone:
-
-        >>> tz_aware = tz_naive.tz_localize(tz='US/Eastern')
-        >>> tz_aware
-        DatetimeIndex(['2018-03-01 09:00:00-05:00',
-                       '2018-03-02 09:00:00-05:00',
-                       '2018-03-03 09:00:00-05:00'],
-                      dtype='datetime64[ns, US/Eastern]', freq='D')
-
-        With the ``tz=None``, we can remove the time zone information
-        while keeping the local time (not converted to UTC):
-
-        >>> tz_aware.tz_localize(None)
-        DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',
-                       '2018-03-03 09:00:00'],
-                      dtype='datetime64[ns]', freq='D')
-
-        Be careful with DST changes. When there is sequential data, pandas can
-        infer the DST time:
-
-        >>> s = pd.to_datetime(pd.Series(['2018-10-28 01:30:00',
-        ...                               '2018-10-28 02:00:00',
-        ...                               '2018-10-28 02:30:00',
-        ...                               '2018-10-28 02:00:00',
-        ...                               '2018-10-28 02:30:00',
-        ...                               '2018-10-28 03:00:00',
-        ...                               '2018-10-28 03:30:00']))
-        >>> s.dt.tz_localize('CET', ambiguous='infer')
-        0   2018-10-28 01:30:00+02:00
-        1   2018-10-28 02:00:00+02:00
-        2   2018-10-28 02:30:00+02:00
-        3   2018-10-28 02:00:00+01:00
-        4   2018-10-28 02:30:00+01:00
-        5   2018-10-28 03:00:00+01:00
-        6   2018-10-28 03:30:00+01:00
-        dtype: datetime64[ns, CET]
-
-        In some cases, inferring the DST is impossible. In such cases, you can
-        pass an ndarray to the ambiguous parameter to set the DST explicitly
-
-        >>> s = pd.to_datetime(pd.Series(['2018-10-28 01:20:00',
-        ...                               '2018-10-28 02:36:00',
-        ...                               '2018-10-28 03:46:00']))
-        >>> s.dt.tz_localize('CET', ambiguous=np.array([True, True, False]))
-        0   2015-03-29 03:00:00+02:00
-        1   2015-03-29 03:30:00+02:00
-        dtype: datetime64[ns, Europe/Warsaw]
-
-        If the DST transition causes nonexistent times, you can shift these
-        dates forward or backwards with a timedelta object or `'shift_forward'`
-        or `'shift_backwards'`.
-
-        >>> s = pd.to_datetime(pd.Series(['2015-03-29 02:30:00',
-        ...                               '2015-03-29 03:30:00']))
-        >>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
-        0   2015-03-29 03:00:00+02:00
-        1   2015-03-29 03:30:00+02:00
-        dtype: datetime64[ns, 'Europe/Warsaw']
-        >>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_backward')
-        0   2015-03-29 01:59:59.999999999+01:00
-        1   2015-03-29 03:30:00+02:00
-        dtype: datetime64[ns, 'Europe/Warsaw']
-        >>> s.dt.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))
-        0   2015-03-29 03:30:00+02:00
-        1   2015-03-29 03:30:00+02:00
-        dtype: datetime64[ns, 'Europe/Warsaw']
-        """
-        nonexistent_options = ("raise", "NaT", "shift_forward", "shift_backward")
-        if nonexistent not in nonexistent_options and not isinstance(
-            nonexistent, timedelta
-        ):
-            raise ValueError(
-                "The nonexistent argument must be one of 'raise', "
-                "'NaT', 'shift_forward', 'shift_backward' or "
-                "a timedelta object"
-            )
+    Returns
+    -------
+    Index-like of parsed dates
+    """
+    from pandas import DatetimeIndex
+    from pandas.core.arrays.datetimes import (
+        maybe_convert_dtype,
+        objects_to_datetime64ns,
+    )
 
-        if self.tz is not None:
-            if tz is None:
-                new_dates = tzconversion.tz_convert(self.asi8, timezones.UTC, self.tz)
-            else:
-                raise TypeError("Already tz-aware, use tz_convert to convert.")
+    if isinstance(arg, (list, tuple)):
+        arg = np.array(arg, dtype="O")
+
+    # these are shortcutable
+    if is_datetime64tz_dtype(arg):
+        if not isinstance(arg, (DatetimeArray, DatetimeIndex)):
+            return DatetimeIndex(arg, tz=tz, name=name)
+        if tz == "utc":
+            # error: Item "DatetimeIndex" of "Union[DatetimeArray, DatetimeIndex]" has
+            # no attribute "tz_convert"
+            arg = arg.tz_convert(None).tz_localize(tz)  # type: ignore
+        return arg
+
+    elif is_datetime64_ns_dtype(arg):
+        if not isinstance(arg, (DatetimeArray, DatetimeIndex)):
+            try:
+                return DatetimeIndex(arg, tz=tz, name=name)
+            except ValueError:
+                pass
+        elif tz:
+            # DatetimeArray, DatetimeIndex
+            # error: Item "DatetimeIndex" of "Union[DatetimeArray, DatetimeIndex]" has
+            # no attribute "tz_localize"
+            return arg.tz_localize(tz)  # type: ignore
+
+        return arg
+
+    elif unit is not None:
+        if format is not None:
+            raise ValueError("cannot specify both format and unit")
+        arg = getattr(arg, "_values", arg)
+
+        # GH 30050 pass an ndarray to tslib.array_with_unit_to_datetime
+        # because it expects an ndarray argument
+        if isinstance(arg, IntegerArray):
+            result = arg.astype(f"datetime64[{unit}]")
+            tz_parsed = None
         else:
-            tz = timezones.maybe_get_tz(tz)
-            # Convert to UTC
 
-            new_dates = conversion.tz_localize_to_utc(
-                self.asi8, tz, ambiguous=ambiguous, nonexistent=nonexistent
+            result, tz_parsed = tslib.array_with_unit_to_datetime(
+                arg, unit, errors=errors
             )
-        new_dates = new_dates.view(_NS_DTYPE)
-        dtype = tz_to_dtype(tz)
-        return self._simple_new(new_dates, dtype=dtype, freq=self.freq)
-
-    # ----------------------------------------------------------------
-    # Conversion Methods - Vectorized analogues of Timestamp methods
-
-    def to_pydatetime(self) -> np.ndarray:
-        """
-        Return Datetime Array/Index as object ndarray of datetime.datetime
-        objects.
-
-        Returns
-        -------
-        datetimes : ndarray
-        """
-        return tslib.ints_to_pydatetime(self.asi8, tz=self.tz)
-
-    def normalize(self):
-        """
-        Convert times to midnight.
-
-        The time component of the date-time is converted to midnight i.e.
-        00:00:00. This is useful in cases, when the time does not matter.
-        Length is unaltered. The timezones are unaffected.
-
-        This method is available on Series with datetime values under
-        the ``.dt`` accessor, and directly on Datetime Array/Index.
-
-        Returns
-        -------
-        DatetimeArray, DatetimeIndex or Series
-            The same type as the original data. Series will have the same
-            name and index. DatetimeIndex will have the same name.
-
-        See Also
-        --------
-        floor : Floor the datetimes to the specified freq.
-        ceil : Ceil the datetimes to the specified freq.
-        round : Round the datetimes to the specified freq.
-
-        Examples
-        --------
-        >>> idx = pd.date_range(start='2014-08-01 10:00', freq='H',
-        ...                     periods=3, tz='Asia/Calcutta')
-        >>> idx
-        DatetimeIndex(['2014-08-01 10:00:00+05:30',
-                       '2014-08-01 11:00:00+05:30',
-                       '2014-08-01 12:00:00+05:30'],
-                        dtype='datetime64[ns, Asia/Calcutta]', freq='H')
-        >>> idx.normalize()
-        DatetimeIndex(['2014-08-01 00:00:00+05:30',
-                       '2014-08-01 00:00:00+05:30',
-                       '2014-08-01 00:00:00+05:30'],
-                       dtype='datetime64[ns, Asia/Calcutta]', freq=None)
-        """
-        if self.tz is None or timezones.is_utc(self.tz):
-            not_null = ~self.isna()
-            DAY_NS = ccalendar.DAY_SECONDS * 1_000_000_000
-            new_values = self.asi8.copy()
-            adjustment = new_values[not_null] % DAY_NS
-            new_values[not_null] = new_values[not_null] - adjustment
-        else:
-            new_values = conversion.normalize_i8_timestamps(self.asi8, self.tz)
-        return type(self)._from_sequence(new_values, freq="infer").tz_localize(self.tz)
-
-    def to_period(self, freq=None):
-        """
-        Cast to PeriodArray/Index at a particular frequency.
-
-        Converts DatetimeArray/Index to PeriodArray/Index.
-
-        Parameters
-        ----------
-        freq : str or Offset, optional
-            One of pandas' :ref:`offset strings <timeseries.offset_aliases>`
-            or an Offset object. Will be inferred by default.
-
-        Returns
-        -------
-        PeriodArray/Index
-
-        Raises
-        ------
-        ValueError
-            When converting a DatetimeArray/Index with non-regular values,
-            so that a frequency cannot be inferred.
-
-        See Also
-        --------
-        PeriodIndex: Immutable ndarray holding ordinal values.
-        DatetimeIndex.to_pydatetime: Return DatetimeIndex as object.
-
-        Examples
-        --------
-        >>> df = pd.DataFrame({"y": [1, 2, 3]},
-        ...                   index=pd.to_datetime(["2000-03-31 00:00:00",
-        ...                                         "2000-05-31 00:00:00",
-        ...                                         "2000-08-31 00:00:00"]))
-        >>> df.index.to_period("M")
-        PeriodIndex(['2000-03', '2000-05', '2000-08'],
-                    dtype='period[M]', freq='M')
-
-        Infer the daily frequency
-
-        >>> idx = pd.date_range("2017-01-01", periods=2)
-        >>> idx.to_period()
-        PeriodIndex(['2017-01-01', '2017-01-02'],
-                    dtype='period[D]', freq='D')
-        """
-        from pandas.core.arrays import PeriodArray
-
-        if self.tz is not None:
-            warnings.warn(
-                "Converting to PeriodArray/Index representation "
-                "will drop timezone information.",
-                UserWarning,
-            )
-
-        if freq is None:
-            freq = self.freqstr or self.inferred_freq
-
-            if freq is None:
-                raise ValueError(
-                    "You must pass a freq argument as current index has none."
-                )
 
-            freq = get_period_alias(freq)
+        if errors == "ignore":
+            from pandas import Index
 
-        return PeriodArray._from_datetime64(self._data, freq, tz=self.tz)
-
-    def to_perioddelta(self, freq):
-        """
-        Calculate TimedeltaArray of difference between index
-        values and index converted to PeriodArray at specified
-        freq. Used for vectorized offsets.
-
-        Parameters
-        ----------
-        freq : Period frequency
-
-        Returns
-        -------
-        TimedeltaArray/Index
-        """
-        # TODO: consider privatizing (discussion in GH#23113)
-        from pandas.core.arrays.timedeltas import TimedeltaArray
-
-        i8delta = self.asi8 - self.to_period(freq).to_timestamp().asi8
-        m8delta = i8delta.view("m8[ns]")
-        return TimedeltaArray(m8delta)
-
-    # -----------------------------------------------------------------
-    # Properties - Vectorized Timestamp Properties/Methods
-
-    def month_name(self, locale=None):
-        """
-        Return the month names of the DateTimeIndex with specified locale.
-
-        .. versionadded:: 0.23.0
-
-        Parameters
-        ----------
-        locale : str, optional
-            Locale determining the language in which to return the month name.
-            Default is English locale.
-
-        Returns
-        -------
-        Index
-            Index of month names.
-
-        Examples
-        --------
-        >>> idx = pd.date_range(start='2018-01', freq='M', periods=3)
-        >>> idx
-        DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31'],
-                      dtype='datetime64[ns]', freq='M')
-        >>> idx.month_name()
-        Index(['January', 'February', 'March'], dtype='object')
-        """
-        if self.tz is not None and not timezones.is_utc(self.tz):
-            values = self._local_timestamps()
+            result = Index(result, name=name)
         else:
-            values = self.asi8
-
-        result = fields.get_date_name_field(values, "month_name", locale=locale)
-        result = self._maybe_mask_results(result, fill_value=None)
-        return result
-
-    def day_name(self, locale=None):
-        """
-        Return the day names of the DateTimeIndex with specified locale.
-
-        .. versionadded:: 0.23.0
-
-        Parameters
-        ----------
-        locale : str, optional
-            Locale determining the language in which to return the day name.
-            Default is English locale.
-
-        Returns
-        -------
-        Index
-            Index of day names.
-
-        Examples
-        --------
-        >>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)
-        >>> idx
-        DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],
-                      dtype='datetime64[ns]', freq='D')
-        >>> idx.day_name()
-        Index(['Monday', 'Tuesday', 'Wednesday'], dtype='object')
-        """
-        if self.tz is not None and not timezones.is_utc(self.tz):
-            values = self._local_timestamps()
-        else:
-            values = self.asi8
-
-        result = fields.get_date_name_field(values, "day_name", locale=locale)
-        result = self._maybe_mask_results(result, fill_value=None)
+            result = DatetimeIndex(result, name=name)
+        # GH 23758: We may still need to localize the result with tz
+        # GH 25546: Apply tz_parsed first (from arg), then tz (from caller)
+        # result will be naive but in UTC
+        try:
+            result = result.tz_localize("UTC").tz_convert(tz_parsed)
+        except AttributeError:
+            # Regular Index from 'ignore' path
+            return result
+        if tz is not None:
+            if result.tz is None:
+                result = result.tz_localize(tz)
+            else:
+                result = result.tz_convert(tz)
         return result
+    elif getattr(arg, "ndim", 1) > 1:
+        raise TypeError(
+            "arg must be a string, datetime, list, tuple, 1-d array, or Series"
+        )
 
-    @property
-    def time(self):
-        """
-        Returns numpy array of datetime.time. The time part of the Timestamps.
-        """
-        # If the Timestamps have a timezone that is not UTC,
-        # convert them into their i8 representation while
-        # keeping their timezone and not using UTC
-        if self.tz is not None and not timezones.is_utc(self.tz):
-            timestamps = self._local_timestamps()
-        else:
-            timestamps = self.asi8
-
-        return tslib.ints_to_pydatetime(timestamps, box="time")
-
-    @property
-    def timetz(self):
-        """
-        Returns numpy array of datetime.time also containing timezone
-        information. The time part of the Timestamps.
-        """
-        return tslib.ints_to_pydatetime(self.asi8, self.tz, box="time")
-
-    @property
-    def date(self):
-        """
-        Returns numpy array of python datetime.date objects (namely, the date
-        part of Timestamps without timezone information).
-        """
-        # If the Timestamps have a timezone that is not UTC,
-        # convert them into their i8 representation while
-        # keeping their timezone and not using UTC
-        if self.tz is not None and not timezones.is_utc(self.tz):
-            timestamps = self._local_timestamps()
-        else:
-            timestamps = self.asi8
-
-        return tslib.ints_to_pydatetime(timestamps, box="date")
-
-    year = _field_accessor(
-        "year",
-        "Y",
-        """
-        The year of the datetime.
-        """,
-    )
-    month = _field_accessor(
-        "month",
-        "M",
-        """
-        The month as January=1, December=12.
-        """,
-    )
-    day = _field_accessor(
-        "day",
-        "D",
-        """
-        The day of the datetime.
-        """,
-    )
-    hour = _field_accessor(
-        "hour",
-        "h",
-        """
-        The hours of the datetime.
-        """,
-    )
-    minute = _field_accessor(
-        "minute",
-        "m",
-        """
-        The minutes of the datetime.
-        """,
-    )
-    second = _field_accessor(
-        "second",
-        "s",
-        """
-        The seconds of the datetime.
-        """,
-    )
-    microsecond = _field_accessor(
-        "microsecond",
-        "us",
-        """
-        The microseconds of the datetime.
-        """,
-    )
-    nanosecond = _field_accessor(
-        "nanosecond",
-        "ns",
-        """
-        The nanoseconds of the datetime.
-        """,
-    )
-    weekofyear = _field_accessor(
-        "weekofyear",
-        "woy",
-        """
-        The week ordinal of the year.
-        """,
-    )
-    week = weekofyear
-    _dayofweek_doc = """
-    The day of the week with Monday=0, Sunday=6.
-
-    Return the day of the week. It is assumed the week starts on
-    Monday, which is denoted by 0 and ends on Sunday which is denoted
-    by 6. This method is available on both Series with datetime
-    values (using the `dt` accessor) or DatetimeIndex.
-
-    Returns
-    -------
-    Series or Index
-        Containing integers indicating the day number.
+    # warn if passing timedelta64, raise for PeriodDtype
+    # NB: this must come after unit transformation
+    orig_arg = arg
+    try:
+        arg, _ = maybe_convert_dtype(arg, copy=False)
+    except TypeError:
+        if errors == "coerce":
+            result = np.array(["NaT"], dtype="datetime64[ns]").repeat(len(arg))
+            return DatetimeIndex(result, name=name)
+        elif errors == "ignore":
+            from pandas import Index
+
+            result = Index(arg, name=name)
+            return result
+        raise
 
-    See Also
-    --------
-    Series.dt.dayofweek : Alias.
-    Series.dt.weekday : Alias.
-    Series.dt.day_name : Returns the name of the day of the week.
+    arg = ensure_object(arg)
+    require_iso8601 = False
 
-    Examples
-    --------
-    >>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()
-    >>> s.dt.dayofweek
-    2016-12-31    5
-    2017-01-01    6
-    2017-01-02    0
-    2017-01-03    1
-    2017-01-04    2
-    2017-01-05    3
-    2017-01-06    4
-    2017-01-07    5
-    2017-01-08    6
-    Freq: D, dtype: int64
-    """
-    dayofweek = _field_accessor("dayofweek", "dow", _dayofweek_doc)
-    weekday = dayofweek
-
-    dayofyear = _field_accessor(
-        "dayofyear",
-        "doy",
-        """
-        The ordinal day of the year.
-        """,
-    )
-    quarter = _field_accessor(
-        "quarter",
-        "q",
-        """
-        The quarter of the date.
-        """,
-    )
-    days_in_month = _field_accessor(
-        "days_in_month",
-        "dim",
-        """
-        The number of days in the month.
-        """,
-    )
-    daysinmonth = days_in_month
-    _is_month_doc = """
-        Indicates whether the date is the {first_or_last} day of the month.
-
-        Returns
-        -------
-        Series or array
-            For Series, returns a Series with boolean values.
-            For DatetimeIndex, returns a boolean array.
-
-        See Also
-        --------
-        is_month_start : Return a boolean indicating whether the date
-            is the first day of the month.
-        is_month_end : Return a boolean indicating whether the date
-            is the last day of the month.
-
-        Examples
-        --------
-        This method is available on Series with datetime values under
-        the ``.dt`` accessor, and directly on DatetimeIndex.
-
-        >>> s = pd.Series(pd.date_range("2018-02-27", periods=3))
-        >>> s
-        0   2018-02-27
-        1   2018-02-28
-        2   2018-03-01
-        dtype: datetime64[ns]
-        >>> s.dt.is_month_start
-        0    False
-        1    False
-        2    True
-        dtype: bool
-        >>> s.dt.is_month_end
-        0    False
-        1    True
-        2    False
-        dtype: bool
-
-        >>> idx = pd.date_range("2018-02-27", periods=3)
-        >>> idx.is_month_start
-        array([False, False, True])
-        >>> idx.is_month_end
-        array([False, True, False])
-    """
-    is_month_start = _field_accessor(
-        "is_month_start", "is_month_start", _is_month_doc.format(first_or_last="first")
-    )
+    if infer_datetime_format and format is None:
+        format = _guess_datetime_format_for_array(arg, dayfirst=dayfirst)
 
-    is_month_end = _field_accessor(
-        "is_month_end", "is_month_end", _is_month_doc.format(first_or_last="last")
-    )
+    if format is not None:
+        # There is a special fast-path for iso8601 formatted
+        # datetime strings, so in those cases don't use the inferred
+        # format because this path makes process slower in this
+        # special case
+        format_is_iso8601 = _format_is_iso(format)
+        if format_is_iso8601:
+            require_iso8601 = not infer_datetime_format
+            format = None
 
-    is_quarter_start = _field_accessor(
-        "is_quarter_start",
-        "is_quarter_start",
-        """
-        Indicator for whether the date is the first day of a quarter.
-
-        Returns
-        -------
-        is_quarter_start : Series or DatetimeIndex
-            The same type as the original data with boolean values. Series will
-            have the same name and index. DatetimeIndex will have the same
-            name.
-
-        See Also
-        --------
-        quarter : Return the quarter of the date.
-        is_quarter_end : Similar property for indicating the quarter start.
-
-        Examples
-        --------
-        This method is available on Series with datetime values under
-        the ``.dt`` accessor, and directly on DatetimeIndex.
-
-        >>> df = pd.DataFrame({'dates': pd.date_range("2017-03-30",
-        ...                   periods=4)})
-        >>> df.assign(quarter=df.dates.dt.quarter,
-        ...           is_quarter_start=df.dates.dt.is_quarter_start)
-               dates  quarter  is_quarter_start
-        0 2017-03-30        1             False
-        1 2017-03-31        1             False
-        2 2017-04-01        2              True
-        3 2017-04-02        2             False
-
-        >>> idx = pd.date_range('2017-03-30', periods=4)
-        >>> idx
-        DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],
-                      dtype='datetime64[ns]', freq='D')
-
-        >>> idx.is_quarter_start
-        array([False, False,  True, False])
-        """,
-    )
-    is_quarter_end = _field_accessor(
-        "is_quarter_end",
-        "is_quarter_end",
-        """
-        Indicator for whether the date is the last day of a quarter.
-
-        Returns
-        -------
-        is_quarter_end : Series or DatetimeIndex
-            The same type as the original data with boolean values. Series will
-            have the same name and index. DatetimeIndex will have the same
-            name.
-
-        See Also
-        --------
-        quarter : Return the quarter of the date.
-        is_quarter_start : Similar property indicating the quarter start.
-
-        Examples
-        --------
-        This method is available on Series with datetime values under
-        the ``.dt`` accessor, and directly on DatetimeIndex.
-
-        >>> df = pd.DataFrame({'dates': pd.date_range("2017-03-30",
-        ...                    periods=4)})
-        >>> df.assign(quarter=df.dates.dt.quarter,
-        ...           is_quarter_end=df.dates.dt.is_quarter_end)
-               dates  quarter    is_quarter_end
-        0 2017-03-30        1             False
-        1 2017-03-31        1              True
-        2 2017-04-01        2             False
-        3 2017-04-02        2             False
-
-        >>> idx = pd.date_range('2017-03-30', periods=4)
-        >>> idx
-        DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],
-                      dtype='datetime64[ns]', freq='D')
-
-        >>> idx.is_quarter_end
-        array([False,  True, False, False])
-        """,
-    )
-    is_year_start = _field_accessor(
-        "is_year_start",
-        "is_year_start",
-        """
-        Indicate whether the date is the first day of a year.
-
-        Returns
-        -------
-        Series or DatetimeIndex
-            The same type as the original data with boolean values. Series will
-            have the same name and index. DatetimeIndex will have the same
-            name.
-
-        See Also
-        --------
-        is_year_end : Similar property indicating the last day of the year.
-
-        Examples
-        --------
-        This method is available on Series with datetime values under
-        the ``.dt`` accessor, and directly on DatetimeIndex.
-
-        >>> dates = pd.Series(pd.date_range("2017-12-30", periods=3))
-        >>> dates
-        0   2017-12-30
-        1   2017-12-31
-        2   2018-01-01
-        dtype: datetime64[ns]
-
-        >>> dates.dt.is_year_start
-        0    False
-        1    False
-        2    True
-        dtype: bool
-
-        >>> idx = pd.date_range("2017-12-30", periods=3)
-        >>> idx
-        DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],
-                      dtype='datetime64[ns]', freq='D')
-
-        >>> idx.is_year_start
-        array([False, False,  True])
-        """,
-    )
-    is_year_end = _field_accessor(
-        "is_year_end",
-        "is_year_end",
-        """
-        Indicate whether the date is the last day of the year.
-
-        Returns
-        -------
-        Series or DatetimeIndex
-            The same type as the original data with boolean values. Series will
-            have the same name and index. DatetimeIndex will have the same
-            name.
-
-        See Also
-        --------
-        is_year_start : Similar property indicating the start of the year.
-
-        Examples
-        --------
-        This method is available on Series with datetime values under
-        the ``.dt`` accessor, and directly on DatetimeIndex.
-
-        >>> dates = pd.Series(pd.date_range("2017-12-30", periods=3))
-        >>> dates
-        0   2017-12-30
-        1   2017-12-31
-        2   2018-01-01
-        dtype: datetime64[ns]
-
-        >>> dates.dt.is_year_end
-        0    False
-        1     True
-        2    False
-        dtype: bool
-
-        >>> idx = pd.date_range("2017-12-30", periods=3)
-        >>> idx
-        DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],
-                      dtype='datetime64[ns]', freq='D')
-
-        >>> idx.is_year_end
-        array([False,  True, False])
-        """,
-    )
-    is_leap_year = _field_accessor(
-        "is_leap_year",
-        "is_leap_year",
-        """
-        Boolean indicator if the date belongs to a leap year.
-
-        A leap year is a year, which has 366 days (instead of 365) including
-        29th of February as an intercalary day.
-        Leap years are years which are multiples of four with the exception
-        of years divisible by 100 but not by 400.
-
-        Returns
-        -------
-        Series or ndarray
-             Booleans indicating if dates belong to a leap year.
-
-        Examples
-        --------
-        This method is available on Series with datetime values under
-        the ``.dt`` accessor, and directly on DatetimeIndex.
-
-        >>> idx = pd.date_range("2012-01-01", "2015-01-01", freq="Y")
-        >>> idx
-        DatetimeIndex(['2012-12-31', '2013-12-31', '2014-12-31'],
-                      dtype='datetime64[ns]', freq='A-DEC')
-        >>> idx.is_leap_year
-        array([ True, False, False], dtype=bool)
-
-        >>> dates = pd.Series(idx)
-        >>> dates_series
-        0   2012-12-31
-        1   2013-12-31
-        2   2014-12-31
-        dtype: datetime64[ns]
-        >>> dates_series.dt.is_leap_year
-        0     True
-        1    False
-        2    False
-        dtype: bool
-        """,
-    )
+    tz_parsed = None
+    result = None
 
-    def to_julian_date(self):
-        """
-        Convert Datetime Array to float64 ndarray of Julian Dates.
-        0 Julian date is noon January 1, 4713 BC.
-        https://en.wikipedia.org/wiki/Julian_day
-        """
-
-        # http://mysite.verizon.net/aesir_research/date/jdalg2.htm
-        year = np.asarray(self.year)
-        month = np.asarray(self.month)
-        day = np.asarray(self.day)
-        testarr = month < 3
-        year[testarr] -= 1
-        month[testarr] += 12
-        return (
-            day
-            + np.fix((153 * month - 457) / 5)
-            + 365 * year
-            + np.floor(year / 4)
-            - np.floor(year / 100)
-            + np.floor(year / 400)
-            + 1_721_118.5
-            + (
-                self.hour
-                + self.minute / 60.0
-                + self.second / 3600.0
-                + self.microsecond / 3600.0 / 1e6
-                + self.nanosecond / 3600.0 / 1e9
-            )
-            / 24.0
+    if format is not None:
+        try:
+            # shortcut formatting here
+            if format == "%Y%m%d":
+                try:
+                    # pass orig_arg as float-dtype may have been converted to
+                    # datetime64[ns]
+                    orig_arg = ensure_object(orig_arg)
+                    result = _attempt_YYYYMMDD(orig_arg, errors=errors)
+                except (ValueError, TypeError, tslibs.OutOfBoundsDatetime) as err:
+                    raise ValueError(
+                        "cannot convert the input to '%Y%m%d' date format"
+                    ) from err
+
+            # fallback
+            if result is None:
+                try:
+                    result, timezones = array_strptime(
+                        arg, format, exact=exact, errors=errors
+                    )
+                    if "%Z" in format or "%z" in format:
+                        return _return_parsed_timezone_results(
+                            result, timezones, tz, name
+                        )
+                except tslibs.OutOfBoundsDatetime:
+                    if errors == "raise":
+                        raise
+                    elif errors == "coerce":
+                        result = np.empty(arg.shape, dtype="M8[ns]")
+                        iresult = result.view("i8")
+                        iresult.fill(tslibs.iNaT)
+                    else:
+                        result = arg
+                except ValueError:
+                    # if format was inferred, try falling back
+                    # to array_to_datetime - terminate here
+                    # for specified formats
+                    if not infer_datetime_format:
+                        if errors == "raise":
+                            raise
+                        elif errors == "coerce":
+                            result = np.empty(arg.shape, dtype="M8[ns]")
+                            iresult = result.view("i8")
+                            iresult.fill(tslibs.iNaT)
+                        else:
+                            result = arg
+        except ValueError as e:
+            # Fallback to try to convert datetime objects if timezone-aware
+            #  datetime objects are found without passing `utc=True`
+            try:
+                values, tz = conversion.datetime_to_datetime64(arg)
+                dta = DatetimeArray(values, dtype=tz_to_dtype(tz))
+                return DatetimeIndex._simple_new(dta, name=name)
+            except (ValueError, TypeError):
+                raise e
+
+    if result is None:
+        assert format is None or infer_datetime_format
+        utc = tz == "utc"
+        result, tz_parsed = objects_to_datetime64ns(
+            arg,
+            dayfirst=dayfirst,
+            yearfirst=yearfirst,
+            utc=utc,
+            errors=errors,
+            require_iso8601=require_iso8601,
+            allow_object=True,
         )
 
+    if tz_parsed is not None:
+        # We can take a shortcut since the datetime64 numpy array
+        # is in UTC
+        dta = DatetimeArray(result, dtype=tz_to_dtype(tz_parsed))
+        return DatetimeIndex._simple_new(dta, name=name)
 
-# -------------------------------------------------------------------
-# Constructor Helpers
+    utc = tz == "utc"
+    return _box_as_indexlike(result, utc=utc, name=name)
 
 
-def sequence_to_dt64ns(
-    data,
-    dtype=None,
-    copy=False,
-    tz=None,
-    dayfirst=False,
-    yearfirst=False,
-    ambiguous="raise",
-):
+def _adjust_to_origin(arg, origin, unit):
     """
+    Helper function for to_datetime.
+    Adjust input argument to the specified origin
+
     Parameters
     ----------
-    data : list-like
-    dtype : dtype, str, or None, default None
-    copy : bool, default False
-    tz : tzinfo, str, or None, default None
-    dayfirst : bool, default False
-    yearfirst : bool, default False
-    ambiguous : str, bool, or arraylike, default 'raise'
-        See pandas._libs.tslibs.conversion.tz_localize_to_utc.
+    arg : list, tuple, ndarray, Series, Index
+        date to be adjusted
+    origin : 'julian' or Timestamp
+        origin offset for the arg
+    unit : string
+        passed unit from to_datetime, must be 'D'
 
     Returns
     -------
-    result : numpy.ndarray
-        The sequence converted to a numpy array with dtype ``datetime64[ns]``.
-    tz : tzinfo or None
-        Either the user-provided tzinfo or one inferred from the data.
-    inferred_freq : Tick or None
-        The inferred frequency of the sequence.
-
-    Raises
-    ------
-    TypeError : PeriodDType data is passed
+    ndarray or scalar of adjusted date(s)
     """
-
-    inferred_freq = None
-
-    dtype = _validate_dt64_dtype(dtype)
-
-    if not hasattr(data, "dtype"):
-        # e.g. list, tuple
-        if np.ndim(data) == 0:
-            # i.e. generator
-            data = list(data)
-        data = np.asarray(data)
-        copy = False
-    elif isinstance(data, ABCSeries):
-        data = data._values
-    if isinstance(data, ABCPandasArray):
-        data = data.to_numpy()
-
-    if hasattr(data, "freq"):
-        # i.e. DatetimeArray/Index
-        inferred_freq = data.freq
-
-    # if dtype has an embedded tz, capture it
-    tz = validate_tz_from_dtype(dtype, tz)
-
-    if isinstance(data, ABCIndexClass):
-        if data.nlevels > 1:
-            # Without this check, data._data below is None
-            raise TypeError("Cannot create a DatetimeArray from a MultiIndex.")
-        data = data._data
-
-    # By this point we are assured to have either a numpy array or Index
-    data, copy = maybe_convert_dtype(data, copy)
-
-    if is_object_dtype(data) or is_string_dtype(data):
-        # TODO: We do not have tests specific to string-dtypes,
-        #  also complex or categorical or other extension
-        copy = False
-        if lib.infer_dtype(data, skipna=False) == "integer":
-            data = data.astype(np.int64)
-        else:
-            # data comes back here as either i8 to denote UTC timestamps
-            #  or M8[ns] to denote wall times
-            data, inferred_tz = objects_to_datetime64ns(
-                data, dayfirst=dayfirst, yearfirst=yearfirst
-            )
-            tz = maybe_infer_tz(tz, inferred_tz)
-
-    # `data` may have originally been a Categorical[datetime64[ns, tz]],
-    # so we need to handle these types.
-    if is_datetime64tz_dtype(data):
-        # DatetimeArray -> ndarray
-        tz = maybe_infer_tz(tz, data.tz)
-        result = data._data
-
-    elif is_datetime64_dtype(data):
-        # tz-naive DatetimeArray or ndarray[datetime64]
-        data = getattr(data, "_data", data)
-        if data.dtype != _NS_DTYPE:
-            data = conversion.ensure_datetime64ns(data)
-
-        if tz is not None:
-            # Convert tz-naive to UTC
-            tz = timezones.maybe_get_tz(tz)
-            data = conversion.tz_localize_to_utc(
-                data.view("i8"), tz, ambiguous=ambiguous
+    if origin == "julian":
+        original = arg
+        j0 = Timestamp(0).to_julian_date()
+        if unit != "D":
+            raise ValueError("unit must be 'D' for origin='julian'")
+        try:
+            arg = arg - j0
+        except TypeError as err:
+            raise ValueError(
+                "incompatible 'arg' type for given 'origin'='julian'"
+            ) from err
+
+        # preemptively check this for a nice range
+        j_max = Timestamp.max.to_julian_date() - j0
+        j_min = Timestamp.min.to_julian_date() - j0
+        if np.any(arg > j_max) or np.any(arg < j_min):
+            raise tslibs.OutOfBoundsDatetime(
+                f"{original} is Out of Bounds for origin='julian'"
             )
-            data = data.view(_NS_DTYPE)
-
-        assert data.dtype == _NS_DTYPE, data.dtype
-        result = data
-
     else:
-        # must be integer dtype otherwise
-        # assume this data are epoch timestamps
-        if tz:
-            tz = timezones.maybe_get_tz(tz)
-
-        if data.dtype != _INT64_DTYPE:
-            data = data.astype(np.int64, copy=False)
-        result = data.view(_NS_DTYPE)
+        # arg must be numeric
+        if not (
+            (is_scalar(arg) and (is_integer(arg) or is_float(arg)))
+            or is_numeric_dtype(np.asarray(arg))
+        ):
+            raise ValueError(
+                f"'{arg}' is not compatible with origin='{origin}'; "
+                "it must be numeric with a unit specified"
+            )
 
-    if copy:
-        # TODO: should this be deepcopy?
-        result = result.copy()
+        # we are going to offset back to unix / epoch time
+        try:
+            offset = Timestamp(origin)
+        except tslibs.OutOfBoundsDatetime as err:
+            raise tslibs.OutOfBoundsDatetime(
+                f"origin {origin} is Out of Bounds"
+            ) from err
+        except ValueError as err:
+            raise ValueError(
+                f"origin {origin} cannot be converted to a Timestamp"
+            ) from err
 
-    assert isinstance(result, np.ndarray), type(result)
-    assert result.dtype == "M8[ns]", result.dtype
+        if offset.tz is not None:
+            raise ValueError(f"origin offset {offset} must be tz-naive")
+        offset -= Timestamp(0)
 
-    # We have to call this again after possibly inferring a tz above
-    validate_tz_from_dtype(dtype, tz)
+        # convert the offset to the unit of the arg
+        # this should be lossless in terms of precision
+        offset = offset // tslibs.Timedelta(1, unit=unit)
 
-    return result, tz, inferred_freq
+        # scalars & ndarray-like can handle the addition
+        if is_list_like(arg) and not isinstance(
+            arg, (ABCSeries, ABCIndexClass, np.ndarray)
+        ):
+            arg = np.asarray(arg)
+        arg = arg + offset
+    return arg
 
 
-def objects_to_datetime64ns(
-    data,
-    dayfirst,
-    yearfirst,
-    utc=False,
+def to_datetime(
+    arg,
     errors="raise",
-    require_iso8601=False,
-    allow_object=False,
+    dayfirst=False,
+    yearfirst=False,
+    utc=None,
+    format=None,
+    exact=True,
+    unit=None,
+    infer_datetime_format=False,
+    origin="unix",
+    cache=True,
 ):
     """
-    Convert data to array of timestamps.
+    Convert argument to datetime.
 
     Parameters
     ----------
-    data : np.ndarray[object]
-    dayfirst : bool
-    yearfirst : bool
-    utc : bool, default False
-        Whether to convert timezone-aware timestamps to UTC.
-    errors : {'raise', 'ignore', 'coerce'}
-    allow_object : bool
-        Whether to return an object-dtype ndarray instead of raising if the
-        data contains more than one timezone.
+    arg : int, float, str, datetime, list, tuple, 1-d array, Series DataFrame/dict-like
+        The object to convert to a datetime.
+    errors : {'ignore', 'raise', 'coerce'}, default 'raise'
+        - If 'raise', then invalid parsing will raise an exception.
+        - If 'coerce', then invalid parsing will be set as NaT.
+        - If 'ignore', then invalid parsing will return the input.
+    dayfirst : bool, default False
+        Specify a date parse order if `arg` is str or its list-likes.
+        If True, parses dates with the day first, eg 10/11/12 is parsed as
+        2012-11-10.
+        Warning: dayfirst=True is not strict, but will prefer to parse
+        with day first (this is a known bug, based on dateutil behavior).
+    yearfirst : bool, default False
+        Specify a date parse order if `arg` is str or its list-likes.
+
+        - If True parses dates with the year first, eg 10/11/12 is parsed as
+          2010-11-12.
+        - If both dayfirst and yearfirst are True, yearfirst is preceded (same
+          as dateutil).
+
+        Warning: yearfirst=True is not strict, but will prefer to parse
+        with year first (this is a known bug, based on dateutil behavior).
+    utc : bool, default None
+        Return UTC DatetimeIndex if True (converting any tz-aware
+        datetime.datetime objects as well).
+    format : str, default None
+        The strftime to parse time, eg "%d/%m/%Y", note that "%f" will parse
+        all the way up to nanoseconds.
+        See strftime documentation for more information on choices:
+        https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior.
+    exact : bool, True by default
+        Behaves as:
+        - If True, require an exact format match.
+        - If False, allow the format to match anywhere in the target string.
+
+    unit : str, default 'ns'
+        The unit of the arg (D,s,ms,us,ns) denote the unit, which is an
+        integer or float number. This will be based off the origin.
+        Example, with unit='ms' and origin='unix' (the default), this
+        would calculate the number of milliseconds to the unix epoch start.
+    infer_datetime_format : bool, default False
+        If True and no `format` is given, attempt to infer the format of the
+        datetime strings, and if it can be inferred, switch to a faster
+        method of parsing them. In some cases this can increase the parsing
+        speed by ~5-10x.
+    origin : scalar, default 'unix'
+        Define the reference date. The numeric values would be parsed as number
+        of units (defined by `unit`) since this reference date.
+
+        - If 'unix' (or POSIX) time; origin is set to 1970-01-01.
+        - If 'julian', unit must be 'D', and origin is set to beginning of
+          Julian Calendar. Julian day number 0 is assigned to the day starting
+          at noon on January 1, 4713 BC.
+        - If Timestamp convertible, origin is set to Timestamp identified by
+          origin.
+    cache : bool, default True
+        If True, use a cache of unique, converted dates to apply the datetime
+        conversion. May produce significant speed-up when parsing duplicate
+        date strings, especially ones with timezone offsets. The cache is only
+        used when there are at least 50 values. The presence of out-of-bounds
+        values will render the cache unusable and may slow down parsing.
+
+        .. versionadded:: 0.23.0
+
+        .. versionchanged:: 0.25.0
+            - changed default value from False to True.
 
     Returns
     -------
-    result : ndarray
-        np.int64 dtype if returned values represent UTC timestamps
-        np.datetime64[ns] if returned values represent wall times
-        object if mixed timezones
-    inferred_tz : tzinfo or None
-
-    Raises
-    ------
-    ValueError : if data cannot be converted to datetimes
-    """
-    assert errors in ["raise", "ignore", "coerce"]
+    datetime
+        If parsing succeeded.
+        Return type depends on input:
 
-    # if str-dtype, convert
-    data = np.array(data, copy=False, dtype=np.object_)
+        - list-like: DatetimeIndex
+        - Series: Series of datetime64 dtype
+        - scalar: Timestamp
 
-    try:
-        result, tz_parsed = tslib.array_to_datetime(
-            data,
-            errors=errors,
-            utc=utc,
-            dayfirst=dayfirst,
-            yearfirst=yearfirst,
-            require_iso8601=require_iso8601,
-        )
-    except ValueError as e:
-        try:
-            values, tz_parsed = conversion.datetime_to_datetime64(data)
-            # If tzaware, these values represent unix timestamps, so we
-            #  return them as i8 to distinguish from wall times
-            return values.view("i8"), tz_parsed
-        except (ValueError, TypeError):
-            raise e
+        In case when it is not possible to return designated types (e.g. when
+        any element of input is before Timestamp.min or after Timestamp.max)
+        return will have datetime.datetime type (or corresponding
+        array/Series).
 
-    if tz_parsed is not None:
-        # We can take a shortcut since the datetime64 numpy array
-        #  is in UTC
-        # Return i8 values to denote unix timestamps
-        return result.view("i8"), tz_parsed
-    elif is_datetime64_dtype(result):
-        # returning M8[ns] denotes wall-times; since tz is None
-        #  the distinction is a thin one
-        return result, tz_parsed
-    elif is_object_dtype(result):
-        # GH#23675 when called via `pd.to_datetime`, returning an object-dtype
-        #  array is allowed.  When called via `pd.DatetimeIndex`, we can
-        #  only accept datetime64 dtype, so raise TypeError if object-dtype
-        #  is returned, as that indicates the values can be recognized as
-        #  datetimes but they have conflicting timezones/awareness
-        if allow_object:
-            return result, tz_parsed
-        raise TypeError(result)
-    else:  # pragma: no cover
-        # GH#23675 this TypeError should never be hit, whereas the TypeError
-        #  in the object-dtype branch above is reachable.
-        raise TypeError(result)
-
-
-def maybe_convert_dtype(data, copy):
+    See Also
+    --------
+    DataFrame.astype : Cast argument to a specified dtype.
+    to_timedelta : Convert argument to timedelta.
+    convert_dtypes : Convert dtypes.
+
+    Examples
+    --------
+    Assembling a datetime from multiple columns of a DataFrame. The keys can be
+    common abbreviations like ['year', 'month', 'day', 'minute', 'second',
+    'ms', 'us', 'ns']) or plurals of the same
+
+    >>> df = pd.DataFrame({'year': [2015, 2016],
+    ...                    'month': [2, 3],
+    ...                    'day': [4, 5]})
+    >>> pd.to_datetime(df)
+    0   2015-02-04
+    1   2016-03-05
+    dtype: datetime64[ns]
+
+    If a date does not meet the `timestamp limitations
+    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html
+    #timeseries-timestamp-limits>`_, passing errors='ignore'
+    will return the original input instead of raising any exception.
+
+    Passing errors='coerce' will force an out-of-bounds date to NaT,
+    in addition to forcing non-dates (or non-parseable dates) to NaT.
+
+    >>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')
+    datetime.datetime(1300, 1, 1, 0, 0)
+    >>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')
+    NaT
+
+    Passing infer_datetime_format=True can often-times speedup a parsing
+    if its not an ISO8601 format exactly, but in a regular format.
+
+    >>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)
+    >>> s.head()
+    0    3/11/2000
+    1    3/12/2000
+    2    3/13/2000
+    3    3/11/2000
+    4    3/12/2000
+    dtype: object
+
+    >>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP
+    100 loops, best of 3: 10.4 ms per loop
+
+    >>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP
+    1 loop, best of 3: 471 ms per loop
+
+    Using a unix epoch time
+
+    >>> pd.to_datetime(1490195805, unit='s')
+    Timestamp('2017-03-22 15:16:45')
+    >>> pd.to_datetime(1490195805433502912, unit='ns')
+    Timestamp('2017-03-22 15:16:45.433502912')
+
+    .. warning:: For float arg, precision rounding might happen. To prevent
+        unexpected behavior use a fixed-width exact type.
+
+    Using a non-unix epoch origin
+
+    >>> pd.to_datetime([1, 2, 3], unit='D',
+    ...                origin=pd.Timestamp('1960-01-01'))
+    DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], \
+dtype='datetime64[ns]', freq=None)
+    """
+    if arg is None:
+        return None
+
+    if origin != "unix":
+        arg = _adjust_to_origin(arg, origin, unit)
+
+    tz = "utc" if utc else None
+    convert_listlike = partial(
+        _convert_listlike_datetimes,
+        tz=tz,
+        unit=unit,
+        dayfirst=dayfirst,
+        yearfirst=yearfirst,
+        errors=errors,
+        exact=exact,
+        infer_datetime_format=infer_datetime_format,
+    )
+
+    if isinstance(arg, Timestamp):
+        result = arg
+        if tz is not None:
+            if arg.tz is not None:
+                result = result.tz_convert(tz)
+            else:
+                result = result.tz_localize(tz)
+    elif isinstance(arg, ABCSeries):
+        cache_array = _maybe_cache(arg, format, cache, convert_listlike)
+        if not cache_array.empty:
+            result = arg.map(cache_array)
+        else:
+            values = convert_listlike(arg._values, format)
+            result = arg._constructor(values, index=arg.index, name=arg.name)
+    elif isinstance(arg, (ABCDataFrame, abc.MutableMapping)):
+        result = _assemble_from_unit_mappings(arg, errors, tz)
+    elif isinstance(arg, ABCIndexClass):
+        cache_array = _maybe_cache(arg, format, cache, convert_listlike)
+        if not cache_array.empty:
+            result = _convert_and_box_cache(arg, cache_array, name=arg.name)
+        else:
+            convert_listlike = partial(convert_listlike, name=arg.name)
+            result = convert_listlike(arg, format)
+    elif is_list_like(arg):
+        try:
+            cache_array = _maybe_cache(arg, format, cache, convert_listlike)
+        except tslibs.OutOfBoundsDatetime:
+            # caching attempts to create a DatetimeIndex, which may raise
+            # an OOB. If that's the desired behavior, then just reraise...
+            if errors == "raise":
+                raise
+            # ... otherwise, continue without the cache.
+            from pandas import Series
+
+            cache_array = Series([], dtype=object)  # just an empty array
+        if not cache_array.empty:
+            result = _convert_and_box_cache(arg, cache_array)
+        else:
+            result = convert_listlike(arg, format)
+    else:
+        result = convert_listlike(np.array([arg]), format)[0]
+
+    return result
+
+
+# mappings for assembling units
+_unit_map = {
+    "year": "year",
+    "years": "year",
+    "month": "month",
+    "months": "month",
+    "day": "day",
+    "days": "day",
+    "hour": "h",
+    "hours": "h",
+    "minute": "m",
+    "minutes": "m",
+    "second": "s",
+    "seconds": "s",
+    "ms": "ms",
+    "millisecond": "ms",
+    "milliseconds": "ms",
+    "us": "us",
+    "microsecond": "us",
+    "microseconds": "us",
+    "ns": "ns",
+    "nanosecond": "ns",
+    "nanoseconds": "ns",
+}
+
+
+def _assemble_from_unit_mappings(arg, errors, tz):
     """
-    Convert data based on dtype conventions, issuing deprecation warnings
-    or errors where appropriate.
+    assemble the unit specified fields from the arg (DataFrame)
+    Return a Series for actual parsing
 
     Parameters
     ----------
-    data : np.ndarray or pd.Index
-    copy : bool
+    arg : DataFrame
+    errors : {'ignore', 'raise', 'coerce'}, default 'raise'
+
+        - If 'raise', then invalid parsing will raise an exception
+        - If 'coerce', then invalid parsing will be set as NaT
+        - If 'ignore', then invalid parsing will return the input
+    tz : None or 'utc'
 
     Returns
     -------
-    data : np.ndarray or pd.Index
-    copy : bool
-
-    Raises
-    ------
-    TypeError : PeriodDType data is passed
+    Series
     """
-    if is_float_dtype(data):
-        # Note: we must cast to datetime64[ns] here in order to treat these
-        #  as wall-times instead of UTC timestamps.
-        data = data.astype(_NS_DTYPE)
-        copy = False
-        # TODO: deprecate this behavior to instead treat symmetrically
-        #  with integer dtypes.  See discussion in GH#23675
-
-    elif is_timedelta64_dtype(data):
-        # GH#29794 enforcing deprecation introduced in GH#23539
-        raise TypeError(f"dtype {data.dtype} cannot be converted to datetime64[ns]")
-    elif is_period_dtype(data):
-        # Note: without explicitly raising here, PeriodIndex
-        #  test_setops.test_join_does_not_recur fails
-        raise TypeError(
-            "Passing PeriodDtype data is invalid. Use `data.to_timestamp()` instead"
+    from pandas import to_timedelta, to_numeric, DataFrame
+
+    arg = DataFrame(arg)
+    if not arg.columns.is_unique:
+        raise ValueError("cannot assemble with duplicate keys")
+
+    # replace passed unit with _unit_map
+    def f(value):
+        if value in _unit_map:
+            return _unit_map[value]
+
+        # m is case significant
+        if value.lower() in _unit_map:
+            return _unit_map[value.lower()]
+
+        return value
+
+    unit = {k: f(k) for k in arg.keys()}
+    unit_rev = {v: k for k, v in unit.items()}
+
+    # we require at least Ymd
+    required = ["year", "month", "day"]
+    req = sorted(set(required) - set(unit_rev.keys()))
+    if len(req):
+        _required = ",".join(req)
+        raise ValueError(
+            "to assemble mappings requires at least that "
+            f"[year, month, day] be specified: [{_required}] is missing"
         )
 
-    elif is_categorical_dtype(data):
-        # GH#18664 preserve tz in going DTI->Categorical->DTI
-        # TODO: cases where we need to do another pass through this func,
-        #  e.g. the categories are timedelta64s
-        data = data.categories.take(data.codes, fill_value=NaT)._values
-        copy = False
+    # keys we don't recognize
+    excess = sorted(set(unit_rev.keys()) - set(_unit_map.values()))
+    if len(excess):
+        _excess = ",".join(excess)
+        raise ValueError(
+            f"extra keys have been passed to the datetime assemblage: [{_excess}]"
+        )
 
-    elif is_extension_array_dtype(data) and not is_datetime64tz_dtype(data):
-        # Includes categorical
-        # TODO: We have no tests for these
-        data = np.array(data, dtype=np.object_)
-        copy = False
+    def coerce(values):
+        # we allow coercion to if errors allows
+        values = to_numeric(values, errors=errors)
 
-    return data, copy
+        # prevent overflow in case of int8 or int16
+        if is_integer_dtype(values):
+            values = values.astype("int64", copy=False)
+        return values
 
+    values = (
+        coerce(arg[unit_rev["year"]]) * 10000
+        + coerce(arg[unit_rev["month"]]) * 100
+        + coerce(arg[unit_rev["day"]])
+    )
+    try:
+        values = to_datetime(values, format="%Y%m%d", errors=errors, utc=tz)
+    except (TypeError, ValueError) as err:
+        raise ValueError(f"cannot assemble the datetimes: {err}") from err
 
-# -------------------------------------------------------------------
-# Validation and Inference
+    for u in ["h", "m", "s", "ms", "us", "ns"]:
+        value = unit_rev.get(u)
+        if value is not None and value in arg:
+            try:
+                values += to_timedelta(coerce(arg[value]), unit=u, errors=errors)
+            except (TypeError, ValueError) as err:
+                raise ValueError(
+                    f"cannot assemble the datetimes [{value}]: {err}"
+                ) from err
+    return values
 
 
-def maybe_infer_tz(tz, inferred_tz):
+def _attempt_YYYYMMDD(arg, errors):
     """
-    If a timezone is inferred from data, check that it is compatible with
-    the user-provided timezone, if any.
+    try to parse the YYYYMMDD/%Y%m%d format, try to deal with NaT-like,
+    arg is a passed in as an object dtype, but could really be ints/strings
+    with nan-like/or floats (e.g. with nan)
 
     Parameters
     ----------
-    tz : tzinfo or None
-    inferred_tz : tzinfo or None
-
-    Returns
-    -------
-    tz : tzinfo or None
-
-    Raises
-    ------
-    TypeError : if both timezones are present but do not match
+    arg : passed value
+    errors : 'raise','ignore','coerce'
     """
-    if tz is None:
-        tz = inferred_tz
-    elif inferred_tz is None:
-        pass
-    elif not timezones.tz_compare(tz, inferred_tz):
-        raise TypeError(
-            f"data is already tz-aware {inferred_tz}, unable to "
-            f"set specified tz: {tz}"
+
+    def calc(carg):
+        # calculate the actual result
+        carg = carg.astype(object)
+        parsed = parsing.try_parse_year_month_day(
+            carg / 10000, carg / 100 % 100, carg % 100
         )
-    return tz
+        return tslib.array_to_datetime(parsed, errors=errors)[0]
 
+    def calc_with_mask(carg, mask):
+        result = np.empty(carg.shape, dtype="M8[ns]")
+        iresult = result.view("i8")
+        iresult[~mask] = tslibs.iNaT
 
-def _validate_dt64_dtype(dtype):
-    """
-    Check that a dtype, if passed, represents either a numpy datetime64[ns]
-    dtype or a pandas DatetimeTZDtype.
-
-    Parameters
-    ----------
-    dtype : object
-
-    Returns
-    -------
-    dtype : None, numpy.dtype, or DatetimeTZDtype
+        masked_result = calc(carg[mask].astype(np.float64).astype(np.int64))
+        result[mask] = masked_result.astype("M8[ns]")
+        return result
 
-    Raises
-    ------
-    ValueError : invalid dtype
+    # try intlike / strings that are ints
+    try:
+        return calc(arg.astype(np.int64))
+    except (ValueError, OverflowError, TypeError):
+        pass
 
-    Notes
-    -----
-    Unlike validate_tz_from_dtype, this does _not_ allow non-existent
-    tz errors to go through
-    """
-    if dtype is not None:
-        dtype = pandas_dtype(dtype)
-        if is_dtype_equal(dtype, np.dtype("M8")):
-            # no precision, disallowed GH#24806
-            msg = (
-                "Passing in 'datetime64' dtype with no precision is not allowed. "
-                "Please pass in 'datetime64[ns]' instead."
-            )
-            raise ValueError(msg)
+    # a float with actual np.nan
+    try:
+        carg = arg.astype(np.float64)
+        return calc_with_mask(carg, notna(carg))
+    except (ValueError, OverflowError, TypeError):
+        pass
 
-        if (isinstance(dtype, np.dtype) and dtype != _NS_DTYPE) or not isinstance(
-            dtype, (np.dtype, DatetimeTZDtype)
-        ):
-            raise ValueError(
-                f"Unexpected value for 'dtype': '{dtype}'. "
-                "Must be 'datetime64[ns]' or DatetimeTZDtype'."
-            )
-    return dtype
+    # string with NaN-like
+    try:
+        mask = ~algorithms.isin(arg, list(tslib.nat_strings))
+        return calc_with_mask(arg, mask)
+    except (ValueError, OverflowError, TypeError):
+        pass
 
+    return None
 
-def validate_tz_from_dtype(dtype, tz):
-    """
-    If the given dtype is a DatetimeTZDtype, extract the implied
-    tzinfo object from it and check that it does not conflict with the given
-    tz.
 
-    Parameters
-    ----------
-    dtype : dtype, str
-    tz : None, tzinfo
+# Fixed time formats for time parsing
+_time_formats = [
+    "%H:%M",
+    "%H%M",
+    "%I:%M%p",
+    "%I%M%p",
+    "%H:%M:%S",
+    "%H%M%S",
+    "%I:%M:%S%p",
+    "%I%M%S%p",
+]
 
-    Returns
-    -------
-    tz : consensus tzinfo
 
-    Raises
-    ------
-    ValueError : on tzinfo mismatch
-    """
-    if dtype is not None:
-        if isinstance(dtype, str):
+def _guess_time_format_for_array(arr):
+    # Try to guess the format based on the first non-NaN element
+    non_nan_elements = notna(arr).nonzero()[0]
+    if len(non_nan_elements):
+        element = arr[non_nan_elements[0]]
+        for time_format in _time_formats:
             try:
-                dtype = DatetimeTZDtype.construct_from_string(dtype)
-            except TypeError:
-                # Things like `datetime64[ns]`, which is OK for the
-                # constructors, but also nonsense, which should be validated
-                # but not by us. We *do* allow non-existent tz errors to
-                # go through
+                datetime.strptime(element, time_format)
+                return time_format
+            except ValueError:
                 pass
-        dtz = getattr(dtype, "tz", None)
-        if dtz is not None:
-            if tz is not None and not timezones.tz_compare(tz, dtz):
-                raise ValueError("cannot supply both a tz and a dtype with a tz")
-            tz = dtz
-
-        if tz is not None and is_datetime64_dtype(dtype):
-            # We also need to check for the case where the user passed a
-            #  tz-naive dtype (i.e. datetime64[ns])
-            if tz is not None and not timezones.tz_compare(tz, dtz):
-                raise ValueError(
-                    "cannot supply both a tz and a "
-                    "timezone-naive dtype (i.e. datetime64[ns])"
-                )
 
-    return tz
+    return None
 
 
-def _infer_tz_from_endpoints(start, end, tz):
+def to_time(arg, format=None, infer_time_format=False, errors="raise"):
     """
-    If a timezone is not explicitly given via `tz`, see if one can
-    be inferred from the `start` and `end` endpoints.  If more than one
-    of these inputs provides a timezone, require that they all agree.
+    Parse time strings to time objects using fixed strptime formats ("%H:%M",
+    "%H%M", "%I:%M%p", "%I%M%p", "%H:%M:%S", "%H%M%S", "%I:%M:%S%p",
+    "%I%M%S%p")
+
+    Use infer_time_format if all the strings are in the same format to speed
+    up conversion.
 
     Parameters
     ----------
-    start : Timestamp
-    end : Timestamp
-    tz : tzinfo or None
+    arg : string in time format, datetime.time, list, tuple, 1-d array,  Series
+    format : str, default None
+        Format used to convert arg into a time object.  If None, fixed formats
+        are used.
+    infer_time_format: bool, default False
+        Infer the time format based on the first non-NaN element.  If all
+        strings are in the same format, this will speed up conversion.
+    errors : {'ignore', 'raise', 'coerce'}, default 'raise'
+        - If 'raise', then invalid parsing will raise an exception
+        - If 'coerce', then invalid parsing will be set as None
+        - If 'ignore', then invalid parsing will return the input
 
     Returns
     -------
-    tz : tzinfo or None
-
-    Raises
-    ------
-    TypeError : if start and end timezones do not agree
+    datetime.time
     """
-    try:
-        inferred_tz = timezones.infer_tzinfo(start, end)
-    except AssertionError as err:
-        # infer_tzinfo raises AssertionError if passed mismatched timezones
-        raise TypeError(
-            "Start and end cannot both be tz-aware with different timezones"
-        ) from err
-
-    inferred_tz = timezones.maybe_get_tz(inferred_tz)
-    tz = timezones.maybe_get_tz(tz)
-
-    if tz is not None and inferred_tz is not None:
-        if not timezones.tz_compare(inferred_tz, tz):
-            raise AssertionError("Inferred time zone not equal to passed time zone")
-
-    elif inferred_tz is not None:
-        tz = inferred_tz
-
-    return tz
 
+    def _convert_listlike(arg, format):
 
-def _maybe_normalize_endpoints(start, end, normalize):
-    _normalized = True
+        if isinstance(arg, (list, tuple)):
+            arg = np.array(arg, dtype="O")
 
-    if start is not None:
-        if normalize:
-            start = normalize_date(start)
-            _normalized = True
-        else:
-            _normalized = _normalized and start.time() == _midnight
+        elif getattr(arg, "ndim", 1) > 1:
+            raise TypeError(
+                "arg must be a string, datetime, list, tuple, 1-d array, or Series"
+            )
 
-    if end is not None:
-        if normalize:
-            end = normalize_date(end)
-            _normalized = True
+        arg = ensure_object(arg)
+
+        if infer_time_format and format is None:
+            format = _guess_time_format_for_array(arg)
+
+        times: List[Optional[time]] = []
+        if format is not None:
+            for element in arg:
+                try:
+                    times.append(datetime.strptime(element, format).time())
+                except (ValueError, TypeError) as err:
+                    if errors == "raise":
+                        msg = (
+                            f"Cannot convert {element} to a time with given "
+                            f"format {format}"
+                        )
+                        raise ValueError(msg) from err
+                    elif errors == "ignore":
+                        return arg
+                    else:
+                        times.append(None)
         else:
-            _normalized = _normalized and end.time() == _midnight
-
-    return start, end, _normalized
-
-
-def _maybe_localize_point(ts, is_none, is_not_none, freq, tz, ambiguous, nonexistent):
-    """
-    Localize a start or end Timestamp to the timezone of the corresponding
-    start or end Timestamp
-
-    Parameters
-    ----------
-    ts : start or end Timestamp to potentially localize
-    is_none : argument that should be None
-    is_not_none : argument that should not be None
-    freq : Tick, DateOffset, or None
-    tz : str, timezone object or None
-    ambiguous: str, localization behavior for ambiguous times
-    nonexistent: str, localization behavior for nonexistent times
-
-    Returns
-    -------
-    ts : Timestamp
-    """
-    # Make sure start and end are timezone localized if:
-    # 1) freq = a Timedelta-like frequency (Tick)
-    # 2) freq = None i.e. generating a linspaced range
-    if is_none is None and is_not_none is not None:
-        # Note: We can't ambiguous='infer' a singular ambiguous time; however,
-        # we have historically defaulted ambiguous=False
-        ambiguous = ambiguous if ambiguous != "infer" else False
-        localize_args = {"ambiguous": ambiguous, "nonexistent": nonexistent, "tz": None}
-        if isinstance(freq, Tick) or freq is None:
-            localize_args["tz"] = tz
-        ts = ts.tz_localize(**localize_args)
-    return ts
+            formats = _time_formats[:]
+            format_found = False
+            for element in arg:
+                time_object = None
+                for time_format in formats:
+                    try:
+                        time_object = datetime.strptime(element, time_format).time()
+                        if not format_found:
+                            # Put the found format in front
+                            fmt = formats.pop(formats.index(time_format))
+                            formats.insert(0, fmt)
+                            format_found = True
+                        break
+                    except (ValueError, TypeError):
+                        continue
+
+                if time_object is not None:
+                    times.append(time_object)
+                elif errors == "raise":
+                    raise ValueError(f"Cannot convert arg {arg} to a time")
+                elif errors == "ignore":
+                    return arg
+                else:
+                    times.append(None)
+
+        return times
+
+    if arg is None:
+        return arg
+    elif isinstance(arg, time):
+        return arg
+    elif isinstance(arg, ABCSeries):
+        values = _convert_listlike(arg._values, format)
+        return arg._constructor(values, index=arg.index, name=arg.name)
+    elif isinstance(arg, ABCIndexClass):
+        return _convert_listlike(arg, format)
+    elif is_list_like(arg):
+        return _convert_listlike(arg, format)
+
+    return _convert_listlike(np.array([arg]), format)[0]
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 2d8eb9b29..e120695cc 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -2666,9 +2666,9 @@ Name: Max Speed, dtype: float64
                 new_values = [func(lv, other) for lv in self._values]
             new_name = self.name
 
-        if is_categorical_dtype(self.values):
+        if is_categorical_dtype(self.dtype):
             pass
-        elif is_extension_array_dtype(self.values):
+        elif is_extension_array_dtype(self.dtype):
             # The function can return something of any type, so check
             # if the type is compatible with the calling EA.
             new_values = try_cast_to_ea(self._values, new_values)
