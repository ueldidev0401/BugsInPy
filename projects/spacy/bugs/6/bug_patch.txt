diff --git a/spacy/lang/lb/__init__.py b/spacy/lang/lb/__init__.py
index 87058bdea..4fcfaddb4 100644
--- a/spacy/lang/lb/__init__.py
+++ b/spacy/lang/lb/__init__.py
@@ -3,6 +3,7 @@ from __future__ import unicode_literals
 
 from .tokenizer_exceptions import TOKENIZER_EXCEPTIONS
 from .norm_exceptions import NORM_EXCEPTIONS
+from .punctuation import TOKENIZER_INFIXES
 from .lex_attrs import LEX_ATTRS
 from .tag_map import TAG_MAP
 from .stop_words import STOP_WORDS
@@ -24,6 +25,7 @@ class LuxembourgishDefaults(Language.Defaults):
     tokenizer_exceptions = update_exc(BASE_EXCEPTIONS, TOKENIZER_EXCEPTIONS)
     stop_words = STOP_WORDS
     tag_map = TAG_MAP
+    infixes = TOKENIZER_INFIXES
 
 
 class Luxembourgish(Language):
diff --git a/spacy/lang/lb/tokenizer_exceptions.py b/spacy/lang/lb/tokenizer_exceptions.py
index adff9da36..18b58f2b1 100644
--- a/spacy/lang/lb/tokenizer_exceptions.py
+++ b/spacy/lang/lb/tokenizer_exceptions.py
@@ -2,31 +2,15 @@
 from __future__ import unicode_literals
 
 from ...symbols import ORTH, LEMMA, NORM
-from ..punctuation import TOKENIZER_PREFIXES
 
 # TODO
-# tokenize cliticised definite article "d'" as token of its own: d'Kanner > [d'] [Kanner]
 # treat other apostrophes within words as part of the word: [op d'mannst], [fir d'éischt] (= exceptions)
 
-# how to write the tokenisation exeption for the articles d' / D' ? This one is not working.
-_prefixes = [
-    prefix for prefix in TOKENIZER_PREFIXES if prefix not in ["d'", "D'", "d’", "D’"]
-]
-
-
 _exc = {
-    "d'mannst": [
-        {ORTH: "d'", LEMMA: "d'"},
-        {ORTH: "mannst", LEMMA: "mann", NORM: "mann"},
-    ],
-    "d'éischt": [
-        {ORTH: "d'", LEMMA: "d'"},
-        {ORTH: "éischt", LEMMA: "éischt", NORM: "éischt"},
-    ],
+    
 }
 
 # translate / delete what is not necessary
-# what does PRON_LEMMA mean?
 for exc_data in [
     {ORTH: "wgl.", LEMMA: "wann ech gelift", NORM: "wann ech gelieft"},
     {ORTH: "M.", LEMMA: "Monsieur", NORM: "Monsieur"},
@@ -64,6 +48,4 @@ for orth in [
 ]:
     _exc[orth] = [{ORTH: orth}]
 
-
-TOKENIZER_PREFIXES = _prefixes
 TOKENIZER_EXCEPTIONS = _exc
