diff --git a/keras/engine/training.py b/keras/engine/training.py
index 0ccfb572..85ab5e23 100644
--- a/keras/engine/training.py
+++ b/keras/engine/training.py
@@ -844,6 +844,7 @@ class Model(Network):
             initial_epoch=0,
             steps_per_epoch=None,
             validation_steps=None,
+            validation_freq=1,
             **kwargs):
         """Trains the model for a given number of epochs (iterations on a dataset).
 
@@ -926,6 +927,13 @@ class Model(Network):
             validation_steps: Only relevant if `steps_per_epoch`
                 is specified. Total number of steps (batches of samples)
                 to validate before stopping.
+            validation_freq: Only relevant if validation data is provided. Integer
+                or list/tuple/set. If an integer, specifies how many training
+                epochs to run before a new validation run is performed, e.g.
+                `validation_freq=2` runs validation every 2 epochs. If a list,
+                tuple, or set, specifies the epochs on which to run validation,
+                e.g. `validation_freq=[1, 2, 10]` runs validation at the end
+                of the 1st, 2nd, and 10th epochs.
 
         # Returns
             A `History` object. Its `History.history` attribute is
@@ -1044,7 +1052,8 @@ class Model(Network):
                                         callback_metrics=callback_metrics,
                                         initial_epoch=initial_epoch,
                                         steps_per_epoch=steps_per_epoch,
-                                        validation_steps=validation_steps)
+                                        validation_steps=validation_steps,
+                                        validation_freq=validation_freq)
 
     def evaluate(self, x=None, y=None,
                  batch_size=None,
@@ -1300,6 +1309,7 @@ class Model(Network):
                       callbacks=None,
                       validation_data=None,
                       validation_steps=None,
+                      validation_freq=1,
                       class_weight=None,
                       max_queue_size=10,
                       workers=1,
@@ -1369,6 +1379,13 @@ class Model(Network):
                 validation dataset divided by the batch size.
                 Optional for `Sequence`: if unspecified, will use
                 the `len(validation_data)` as a number of steps.
+            validation_freq: Only relevant if validation data is provided. Integer
+                or `collections.Container` instance (e.g. list, tuple, etc.). If an
+                integer, specifies how many training epochs to run before a new
+                validation run is performed, e.g. `validation_freq=2` runs
+                validation every 2 epochs. If a Container, specifies the epochs on
+                which to run validation, e.g. `validation_freq=[1, 2, 10]` runs
+                validation at the end of the 1st, 2nd, and 10th epochs.
             class_weight: Optional dictionary mapping class indices (integers)
                 to a weight (float) value, used for weighting the loss function
                 (during training only). This can be useful to tell the model to
@@ -1428,6 +1445,7 @@ class Model(Network):
             callbacks=callbacks,
             validation_data=validation_data,
             validation_steps=validation_steps,
+            validation_freq=validation_freq,
             class_weight=class_weight,
             max_queue_size=max_queue_size,
             workers=workers,
diff --git a/keras/engine/training_arrays.py b/keras/engine/training_arrays.py
index 0250a9cd..466dd6bf 100644
--- a/keras/engine/training_arrays.py
+++ b/keras/engine/training_arrays.py
@@ -8,8 +8,9 @@ import numpy as np
 from scipy.sparse import issparse
 
 from .training_utils import batch_shuffle
-from .training_utils import make_batches
 from .training_utils import check_num_samples
+from .training_utils import make_batches
+from .training_utils import should_run_validation
 from .. import backend as K
 from .. import callbacks as cbks
 from ..utils.generic_utils import Progbar
@@ -30,7 +31,8 @@ def fit_loop(model, fit_function, fit_inputs,
              callback_metrics=None,
              initial_epoch=0,
              steps_per_epoch=None,
-             validation_steps=None):
+             validation_steps=None,
+             validation_freq=1):
     """Abstract fit function for `fit_function(fit_inputs)`.
 
     Assumes that fit_function returns a list, labeled by out_labels.
@@ -62,6 +64,13 @@ def fit_loop(model, fit_function, fit_inputs,
         validation_steps: Number of steps to run validation for
             (only if doing validation from data tensors).
             Ignored with the default value of `None`.
+        validation_freq: Only relevant if validation data is provided. Integer
+            or list/tuple/set. If an integer, specifies how many training
+            epochs to run before a new validation run is performed, e.g.
+            validation_freq=2` runs validation every 2 epochs. If a list,
+            tuple, or set, specifies the epochs on which to run validation,
+            e.g. `validation_freq=[1, 2, 10]` runs validation at the end
+            of the 1st, 2nd, and 10th epochs.
 
     # Returns
         `History` object.
@@ -158,7 +167,7 @@ def fit_loop(model, fit_function, fit_inputs,
                 if callback_model.stop_training:
                     break
 
-            if do_validation:
+            if do_validation and should_run_validation(validation_freq, epoch):
                 val_outs = test_loop(model, val_function, val_inputs,
                                      steps=validation_steps,
                                      callbacks=callbacks,
@@ -201,16 +210,17 @@ def fit_loop(model, fit_function, fit_inputs,
                 if callbacks.model.stop_training:
                     break
 
-                if batch_index == len(batches) - 1:  # Last batch.
-                    if do_validation:
-                        val_outs = test_loop(model, val_function, val_inputs,
-                                             batch_size=batch_size,
-                                             callbacks=callbacks,
-                                             verbose=0)
-                        val_outs = to_list(val_outs)
-                        # Same labels assumed.
-                        for l, o in zip(out_labels, val_outs):
-                            epoch_logs['val_' + l] = o
+            if batch_index == len(batches) - 1:  # Last batch.
+                if do_validation and should_run_validation(validation_freq, epoch):
+                    val_outs = test_loop(model, val_function, val_inputs,
+                                         batch_size=batch_size,
+                                         callbacks=callbacks,
+                                         verbose=0)
+                    val_outs = to_list(val_outs)
+                    # Same labels assumed.
+                    for l, o in zip(out_labels, val_outs):
+                        epoch_logs['val_' + l] = o
+
         callbacks.on_epoch_end(epoch, epoch_logs)
         if callbacks.model.stop_training:
             break
diff --git a/keras/engine/training_generator.py b/keras/engine/training_generator.py
index cb2b8886..4de75518 100644
--- a/keras/engine/training_generator.py
+++ b/keras/engine/training_generator.py
@@ -9,6 +9,7 @@ import numpy as np
 
 from .training_utils import is_sequence
 from .training_utils import iter_sequence_infinite
+from .training_utils import should_run_validation
 from .. import backend as K
 from ..utils.data_utils import Sequence
 from ..utils.data_utils import GeneratorEnqueuer
@@ -27,6 +28,7 @@ def fit_generator(model,
                   callbacks=None,
                   validation_data=None,
                   validation_steps=None,
+                  validation_freq=1,
                   class_weight=None,
                   max_queue_size=10,
                   workers=1,
@@ -222,7 +224,9 @@ def fit_generator(model,
                 steps_done += 1
 
                 # Epoch finished.
-                if steps_done >= steps_per_epoch and do_validation:
+                if (steps_done >= steps_per_epoch and
+                        do_validation and
+                        should_run_validation(validation_freq, epoch)):
                     # Note that `callbacks` here is an instance of
                     # `keras.callbacks.CallbackList`
                     if val_gen:
diff --git a/keras/engine/training_utils.py b/keras/engine/training_utils.py
index 1effb720..f104af8c 100644
--- a/keras/engine/training_utils.py
+++ b/keras/engine/training_utils.py
@@ -4,6 +4,7 @@ from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
+import collections
 import copy
 import numpy as np
 import warnings
@@ -615,3 +616,33 @@ def is_sequence(seq):
     # TODO Dref360: Decide which pattern to follow. First needs a new TF Version.
     return (getattr(seq, 'use_sequence_api', False)
             or set(dir(Sequence())).issubset(set(dir(seq) + ['use_sequence_api'])))
+
+
+def should_run_validation(validation_freq, epoch):
+    """Checks if validation should be run this epoch.
+
+    Arguments:
+    validation_freq: Integer or list. If an integer, specifies how many training
+      epochs to run before a new validation run is performed. If a list,
+      specifies the epochs on which to run validation.
+    epoch: Integer, the number of the training epoch just completed.
+
+    Returns:
+    Bool, True if validation should be run.
+
+    Raises:
+    ValueError: if `validation_freq` is an Integer and less than 1, or if
+    it is neither an Integer nor a Sequence.
+    """
+    # `epoch` is 0-indexed internally but 1-indexed in the public API.
+    one_indexed_epoch = epoch + 1
+
+    if isinstance(validation_freq, int):
+        if validation_freq < 1:
+            raise ValueError('`validation_freq` can not be less than 1.')
+        return one_indexed_epoch % validation_freq == 0
+
+    if not isinstance(validation_freq, collections.Container):
+        raise ValueError('`validation_freq` must be an Integer or '
+                         '`collections.Container` (e.g. list, tuple, etc.)')
+    return one_indexed_epoch in validation_freq
